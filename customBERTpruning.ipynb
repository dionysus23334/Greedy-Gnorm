{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 下载BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Python\\lib\\site-packages\\huggingface_hub\\repocard.py:105: UserWarning: Repo card metadata block was not found. Setting CardData to empty.\n",
      "  warnings.warn(\"Repo card metadata block was not found. Setting CardData to empty.\")\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from datasets import load_dataset\n",
    "from textpruner import TransformerPruner\n",
    "\n",
    "# Load model directly\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"hw2942/bert-base-chinese-finetuning-financial-news-sentiment-v2\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"hw2942/bert-base-chinese-finetuning-financial-news-sentiment-v2\",output_attentions=True)\n",
    "\n",
    "# load the dataset \n",
    "ds = load_dataset(\"hw2942/financial-news-sentiment\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class BertConfig:\n",
    "    def __init__(self, vocab_size=30522, num_layers=12, embed_size=768, max_position_embeddings=512, \n",
    "                 type_vocab_size=2, intermediate_size=3072, num_labels=3):\n",
    "        self.vocab_size = vocab_size\n",
    "        self.num_layers = num_layers\n",
    "        self.embed_size = embed_size\n",
    "        self.max_position_embeddings = max_position_embeddings\n",
    "        self.type_vocab_size = type_vocab_size\n",
    "        self.intermediate_size = intermediate_size\n",
    "        self.num_labels = num_labels\n",
    "        self.model_type = 'bert'\n",
    "\n",
    "class BertEmbeddings(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, max_position_embeddings, type_vocab_size):\n",
    "        super().__init__()\n",
    "        self.word_embeddings = nn.Embedding(vocab_size, embed_size, padding_idx=0)\n",
    "        self.position_embeddings = nn.Embedding(max_position_embeddings, embed_size)\n",
    "        self.token_type_embeddings = nn.Embedding(type_vocab_size, embed_size)\n",
    "\n",
    "        self.layer_norm = nn.LayerNorm(embed_size, eps=1e-12)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "    def forward(self, input_ids, token_type_ids=None):\n",
    "        seq_length = input_ids.size(1)\n",
    "        position_ids = torch.arange(seq_length, dtype=torch.long, device=input_ids.device)\n",
    "        position_ids = position_ids.unsqueeze(0).expand_as(input_ids)\n",
    "\n",
    "        if token_type_ids is None:\n",
    "            token_type_ids = torch.zeros_like(input_ids)\n",
    "\n",
    "        words_embeddings = self.word_embeddings(input_ids)\n",
    "        position_embeddings = self.position_embeddings(position_ids)\n",
    "        token_type_embeddings = self.token_type_embeddings(token_type_ids)\n",
    "\n",
    "        embeddings = words_embeddings + position_embeddings + token_type_embeddings\n",
    "        embeddings = self.layer_norm(embeddings)\n",
    "        embeddings = self.dropout(embeddings)\n",
    "        return embeddings\n",
    "\n",
    "class BertSelfAttention(nn.Module):\n",
    "    def __init__(self, embed_size):\n",
    "        super().__init__()\n",
    "        self.query = nn.Linear(embed_size, embed_size)\n",
    "        self.key = nn.Linear(embed_size, embed_size)\n",
    "        self.value = nn.Linear(embed_size, embed_size)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "    def forward(self, hidden_states, attention_mask=None):\n",
    "        Q = self.query(hidden_states)\n",
    "        K = self.key(hidden_states)\n",
    "        V = self.value(hidden_states)\n",
    "\n",
    "        attention_scores = torch.matmul(Q, K.transpose(-1, -2)) / torch.sqrt(torch.tensor(embed_size, dtype=torch.float32))\n",
    "        if attention_mask is not None:\n",
    "            attention_scores = attention_scores.masked_fill(attention_mask == 0, float('-inf'))\n",
    "        attention_probs = F.softmax(attention_scores, dim=-1)\n",
    "        attention_probs = self.dropout(attention_probs)\n",
    "\n",
    "        context_layer = torch.matmul(attention_probs, V)\n",
    "        return context_layer\n",
    "\n",
    "class BertSelfOutput(nn.Module):\n",
    "    def __init__(self, embed_size):\n",
    "        super().__init__()\n",
    "        self.dense = nn.Linear(embed_size, embed_size)\n",
    "        self.LayerNorm = nn.LayerNorm(embed_size, eps=1e-12)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "    def forward(self, hidden_states, input_tensor):\n",
    "        hidden_states = self.dense(hidden_states)\n",
    "        hidden_states = self.dropout(hidden_states)\n",
    "        hidden_states = self.LayerNorm(hidden_states + input_tensor)\n",
    "        return hidden_states\n",
    "\n",
    "class BertAttention(nn.Module):\n",
    "    def __init__(self, embed_size):\n",
    "        super().__init__()\n",
    "        self.self = BertSelfAttention(embed_size)\n",
    "        self.output = BertSelfOutput(embed_size)\n",
    "\n",
    "    def forward(self, hidden_states, attention_mask=None):\n",
    "        self_outputs = self.self(hidden_states, attention_mask)\n",
    "        attention_output = self.output(self_outputs, hidden_states)\n",
    "        return attention_output\n",
    "\n",
    "class BertIntermediate(nn.Module):\n",
    "    def __init__(self, embed_size, intermediate_size):\n",
    "        super().__init__()\n",
    "        self.dense = nn.Linear(embed_size, intermediate_size)\n",
    "        self.intermediate_act_fn = nn.GELU()\n",
    "\n",
    "    def forward(self, hidden_states):\n",
    "        hidden_states = self.dense(hidden_states)\n",
    "        hidden_states = self.intermediate_act_fn(hidden_states)\n",
    "        return hidden_states\n",
    "\n",
    "class BertOutput(nn.Module):\n",
    "    def __init__(self, intermediate_size, embed_size):\n",
    "        super().__init__()\n",
    "        self.dense = nn.Linear(intermediate_size, embed_size)\n",
    "        self.LayerNorm = nn.LayerNorm(embed_size, eps=1e-12)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "    def forward(self, hidden_states, input_tensor):\n",
    "        hidden_states = self.dense(hidden_states)\n",
    "        hidden_states = self.dropout(hidden_states)\n",
    "        hidden_states = self.LayerNorm(hidden_states + input_tensor)\n",
    "        return hidden_states\n",
    "\n",
    "class BertLayer(nn.Module):\n",
    "    def __init__(self, embed_size, intermediate_size):\n",
    "        super().__init__()\n",
    "        self.attention = BertAttention(embed_size)\n",
    "        self.intermediate = BertIntermediate(embed_size, intermediate_size)\n",
    "        self.output = BertOutput(intermediate_size, embed_size)\n",
    "\n",
    "    def forward(self, hidden_states, attention_mask=None):\n",
    "        attention_output = self.attention(hidden_states, attention_mask)\n",
    "        intermediate_output = self.intermediate(attention_output)\n",
    "        layer_output = self.output(intermediate_output, attention_output)\n",
    "        return layer_output\n",
    "\n",
    "class BertEncoder(nn.Module):\n",
    "    def __init__(self, num_layers, embed_size, intermediate_size):\n",
    "        super().__init__()\n",
    "        self.layer = nn.ModuleList([BertLayer(embed_size, intermediate_size) for _ in range(num_layers)])\n",
    "\n",
    "    def forward(self, hidden_states, attention_mask=None):\n",
    "        for layer in self.layer:\n",
    "            hidden_states = layer(hidden_states, attention_mask)\n",
    "        return hidden_states\n",
    "\n",
    "class BertPooler(nn.Module):\n",
    "    def __init__(self, embed_size):\n",
    "        super().__init__()\n",
    "        self.dense = nn.Linear(embed_size, embed_size)\n",
    "        self.activation = nn.Tanh()\n",
    "\n",
    "    def forward(self, hidden_states):\n",
    "        # Pooler usually pools the first token (CLS token) hidden state\n",
    "        first_token_tensor = hidden_states[:, 0]\n",
    "        pooled_output = self.dense(first_token_tensor)\n",
    "        pooled_output = self.activation(pooled_output)\n",
    "        return pooled_output\n",
    "\n",
    "class BertModel(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.embeddings = BertEmbeddings(config.vocab_size, config.embed_size, config.max_position_embeddings, config.type_vocab_size)\n",
    "        self.encoder = BertEncoder(config.num_layers, config.embed_size, config.intermediate_size)\n",
    "        self.pooler = BertPooler(config.embed_size)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask=None, token_type_ids=None):\n",
    "        embeddings = self.embeddings(input_ids, token_type_ids)\n",
    "        encoder_output = self.encoder(embeddings, attention_mask)\n",
    "        pooled_output = self.pooler(encoder_output)\n",
    "        return encoder_output, pooled_output\n",
    "\n",
    "class BertForSequenceClassification(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.bert = BertModel(config)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.classifier = nn.Linear(config.embed_size, config.num_labels)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask=None, token_type_ids=None):\n",
    "        _, pooled_output = self.bert(input_ids, attention_mask, token_type_ids)\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.classifier(pooled_output)\n",
    "        return logits\n",
    "\n",
    "# Model instantiation and example\n",
    "vocab_size = 21128  # The size of the vocabulary\n",
    "num_labels = 3      # The number of labels for the classification task\n",
    "num_layers = 12     # Number of transformer layers\n",
    "embed_size = 768    # The size of each embedding vector\n",
    "max_position_embeddings = 512  # The maximum length of the input sequences\n",
    "type_vocab_size = 2  # The size of the token type vocabulary\n",
    "intermediate_size = 3072  # The size of the intermediate (feed forward) layer\n",
    "\n",
    "config = BertConfig(vocab_size=21128, num_layers=12, embed_size=768, max_position_embeddings=512,\n",
    "                    type_vocab_size=2, intermediate_size=3072, num_labels=3)\n",
    "\n",
    "model = BertForSequenceClassification(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Python\\lib\\site-packages\\transformers\\modeling_utils.py:460: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
      "d:\\Python\\lib\\site-packages\\huggingface_hub\\repocard.py:105: UserWarning: Repo card metadata block was not found. Setting CardData to empty.\n",
      "  warnings.warn(\"Repo card metadata block was not found. Setting CardData to empty.\")\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from datasets import load_dataset\n",
    "from textpruner import TransformerPruner\n",
    "\n",
    "# Load model directly\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"hw2942/bert-base-chinese-finetuning-financial-news-sentiment-v2\")\n",
    "bert = AutoModelForSequenceClassification.from_pretrained(\"hw2942/bert-base-chinese-finetuning-financial-news-sentiment-v2\",output_attentions=True)\n",
    "\n",
    "# load the dataset \n",
    "ds = load_dataset(\"hw2942/financial-news-sentiment\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def adjust_keys(state_dict, old_key, new_key):\n",
    "    \"\"\"将状态字典中的键从old_key替换为new_key\"\"\"\n",
    "    new_state_dict = {}\n",
    "    for key, value in state_dict.items():\n",
    "        new_key_name = key.replace(old_key, new_key)\n",
    "        new_state_dict[new_key_name] = value\n",
    "    return new_state_dict\n",
    "\n",
    "# 加载预先保存的模型状态字典\n",
    "state_dict = bert.state_dict()\n",
    "\n",
    "# 调整状态字典中的键名，假设你的模型期望'LayerNorm'而不是'layer_norm'\n",
    "adjusted_state_dict = adjust_keys(state_dict, \"bert.embeddings.LayerNorm.weight\", \"bert.embeddings.layer_norm.weight\")\n",
    "adjusted_state_dict = adjust_keys(adjusted_state_dict, \"bert.embeddings.LayerNorm.bias\", \"bert.embeddings.layer_norm.bias\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(adjusted_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_acc(test_dataset,model_,tokenizer,device='cuda'):\n",
    "    total = 0\n",
    "    right = 0\n",
    "    model_.to(device)\n",
    "    for data in test_dataset:\n",
    "        inputs = tokenizer(data['Title'],return_tensors='pt').to(device)\n",
    "        outputs = model_(**inputs)\n",
    "        total  += 1\n",
    "        if torch.max(outputs[0][0].softmax(0),dim=0).indices==data['labels']:\n",
    "            right += 1\n",
    "    return right/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textpruner import TransformerPruner\n",
    "pruner = TransformerPruner(model,base_model_prefix='bert')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22413052812365822"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset = ds['train']\n",
    "model.eval()  \n",
    "get_acc(test_dataset,model,tokenizer,device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9682267067410906"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_acc(test_dataset,bert,tokenizer,device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3.5746,  0.5193, -3.3148]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to('cpu')\n",
    "inputs = tokenizer(ds['train'][0]['Title'],return_tensors='pt')\n",
    "model.eval()  # 设置为评估模式\n",
    "model(**inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-3.4763,  6.7623, -2.4192]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert.to('cpu')\n",
    "inputs = tokenizer(ds['train'][0]['Title'],return_tensors='pt')\n",
    "bert(**inputs)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertEmbeddings(\n",
       "  (word_embeddings): Embedding(21128, 768, padding_idx=0)\n",
       "  (position_embeddings): Embedding(512, 768)\n",
       "  (token_type_embeddings): Embedding(2, 768)\n",
       "  (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.bert.embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertEmbeddings(\n",
       "  (word_embeddings): Embedding(21128, 768, padding_idx=0)\n",
       "  (position_embeddings): Embedding(512, 768)\n",
       "  (token_type_embeddings): Embedding(2, 768)\n",
       "  (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.bert.embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert.bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[-0.2386, -0.7616, -0.0187,  ...,  0.0816, -1.0815,  0.8051],\n",
       "         [-1.0530, -0.5591,  0.0589,  ...,  0.5825, -0.5621,  0.5845],\n",
       "         [-0.8456, -0.6958,  0.1725,  ...,  0.7389, -0.1613,  0.4166],\n",
       "         ...,\n",
       "         [-0.5311, -0.7683,  0.2420,  ...,  0.1521, -1.4997,  0.7731],\n",
       "         [-0.3663, -1.0121, -0.1525,  ...,  0.2732, -1.1671,  0.9551],\n",
       "         [-0.7145, -0.6862, -0.0597,  ..., -0.0095, -0.9090,  0.3740]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[ 0.6541, -0.9768,  0.4716,  0.8724,  0.7517,  0.9834, -0.9666, -0.8758,\n",
       "         -0.3037, -0.6854, -0.3155, -0.9984, -0.8938, -0.7400,  0.9437, -0.7695,\n",
       "          1.0000,  0.9809, -0.9335,  0.6720,  0.9923,  0.9616, -0.8453, -0.9630,\n",
       "          0.9764, -0.1965, -0.6682, -0.5618,  0.4427, -0.8411, -0.6409,  0.8537,\n",
       "         -0.8919, -0.6777, -0.4055,  0.9908, -0.7387, -0.8960, -0.9827, -0.9881,\n",
       "         -0.7105, -0.6747,  0.5522,  0.4822, -0.4990,  0.7658,  0.3349, -0.3838,\n",
       "         -0.9614,  0.9882, -0.6397, -0.9567, -0.5078,  0.9093,  0.9391, -0.7534,\n",
       "         -0.7547,  0.5059,  0.8535,  0.8283,  0.9570, -0.9878,  0.5419, -0.8905,\n",
       "          0.9844,  0.8652, -0.5336,  0.8207,  0.9571, -0.1660,  0.8385,  0.6719,\n",
       "          0.5597, -0.7419,  0.5758, -0.9916,  0.3054,  0.3574,  0.2636, -0.0823,\n",
       "         -0.5068, -0.9179,  0.9387,  0.6618,  0.6478,  0.8681,  0.3325,  0.8843,\n",
       "         -0.9459, -0.9687, -0.9398, -0.6966,  0.1931,  0.9794, -0.9019,  0.8780,\n",
       "         -0.9881,  0.9780, -0.9377,  0.4944,  0.0120, -0.9124,  0.9923,  0.7847,\n",
       "         -0.9465,  0.5231, -0.7896, -0.9148,  0.6857,  0.9773,  0.5273, -0.7353,\n",
       "          0.9727,  0.6504, -0.1967,  0.9540, -0.5377,  0.5690,  0.7237, -0.0951,\n",
       "         -0.8190,  0.9662, -0.2011, -0.7384,  0.9627,  0.6212, -0.6530,  0.9496,\n",
       "         -0.9939, -0.8920, -0.1163, -0.0612, -0.2480, -0.8373, -0.8894, -0.7591,\n",
       "          0.9713,  0.6461,  0.0873, -0.8255, -0.9683, -0.8273,  0.1481, -0.7617,\n",
       "          0.9470, -0.8589,  0.5953, -0.7554, -0.8214,  0.9331,  0.9778,  0.4216,\n",
       "         -0.8272,  0.4595, -0.8532,  0.9437,  0.9281,  0.8945, -0.9592, -0.6802,\n",
       "          0.6859,  0.9841, -0.9316,  0.8877,  0.5705, -0.7508,  0.9310, -0.0664,\n",
       "         -0.9982, -0.9782, -0.8357,  0.9151, -0.9056,  0.8653,  0.5740,  0.9941,\n",
       "         -0.1726,  0.7624, -0.9981, -0.8089,  0.9380, -0.7415,  0.2170, -0.6362,\n",
       "         -0.7092, -0.4148, -0.9361, -0.9040, -0.9044, -0.6424, -0.9697,  0.9757,\n",
       "          0.8498,  0.5680,  0.9757,  0.9304, -0.9958, -0.9896,  0.3789,  0.9012,\n",
       "         -0.5714, -0.9106,  0.7388, -0.9247,  0.6483, -0.7542, -0.2741, -0.1564,\n",
       "          0.7073,  0.8114, -0.4093,  0.8024,  0.9000,  0.9838, -0.7989, -0.3029,\n",
       "         -0.6993,  0.9820, -0.6210,  0.9230, -0.9603,  0.9168, -0.0658,  0.0381,\n",
       "         -0.8523, -0.9451,  0.9656,  0.2130, -0.9813,  0.8897, -0.3392, -0.9932,\n",
       "          0.7627, -0.6523,  0.9843, -0.9393, -0.9962, -0.8225, -0.1979,  0.9788,\n",
       "          0.1812, -0.9991, -0.2726, -0.8666, -0.1275,  0.3335, -0.6699, -0.8953,\n",
       "         -0.3334, -0.1442, -0.9761,  0.3589, -0.9873, -0.3596, -0.9992,  0.9067,\n",
       "         -0.5435, -0.1535,  0.8345, -0.9869,  0.9868, -0.8653,  0.7194, -0.9172,\n",
       "          0.2388, -0.6457, -0.8964, -0.9500, -0.7960,  0.7183, -0.8641,  0.8932,\n",
       "          0.6698, -0.6830, -0.8003,  0.9809, -0.5548, -0.1538, -0.9913,  0.7435,\n",
       "          0.5390, -0.3408, -0.8692, -0.9859,  0.7095,  0.9106,  0.9002,  0.6473,\n",
       "         -0.7874, -0.2763,  0.9367, -0.8407, -0.8908,  0.9953, -0.5909,  0.6624,\n",
       "          0.9913, -0.5701,  0.6379, -0.9955,  0.8878,  0.9985,  0.9400, -0.9864,\n",
       "          0.6919,  0.7220, -0.9587, -0.9565, -0.9369,  0.9027,  0.3989,  0.5388,\n",
       "          0.2073,  0.9370, -0.1532,  0.0196, -0.8597,  0.8459,  0.9979,  0.9822,\n",
       "         -0.8018,  0.9949, -0.8271, -0.9190, -0.9594,  0.8502, -0.8746, -0.9096,\n",
       "          0.9370,  0.8933, -0.9998,  0.9445, -0.7510, -0.1412,  0.6367,  0.8213,\n",
       "          0.4995,  0.9863,  0.5228, -0.5638, -0.4825,  0.4808,  0.9539, -0.8874,\n",
       "          0.6827, -0.4499,  0.0649, -0.9699,  0.9999,  0.8845, -0.4208,  0.0763,\n",
       "          0.7788, -0.9933, -0.8708, -0.8296,  0.4567,  0.5654,  0.7247,  0.1825,\n",
       "          0.6862,  0.7585,  0.9870, -0.8266, -0.9919, -0.8514,  0.2419, -0.8000,\n",
       "         -0.5337,  0.9185, -0.8217, -0.7267,  0.9442, -0.9667,  0.6943, -0.8350,\n",
       "         -0.9746, -0.5523,  0.9985,  0.8764,  0.9828, -0.9825,  0.4255, -0.7433,\n",
       "          0.3406,  0.2644,  0.3538, -0.5857,  0.4347,  0.2342, -0.7865, -0.9997,\n",
       "         -0.9071, -0.9929,  0.7391, -0.0691,  0.2389,  0.4990,  0.1207,  0.8242,\n",
       "         -0.9815, -0.9109,  0.6306, -0.4703, -0.7443, -0.6849,  0.7236,  0.6557,\n",
       "         -0.9863,  0.5310, -0.9478,  0.1403,  0.8055,  0.8139, -0.6944, -0.7461,\n",
       "          0.1886, -0.0248, -0.9357, -0.9442, -0.9841,  0.9911, -0.9894, -0.0015,\n",
       "          0.9031,  0.3418, -0.9977,  0.9985, -0.6540,  0.9218,  0.8049,  0.6662,\n",
       "          0.9913,  0.0383, -0.9346,  0.8817,  0.9208, -0.9112, -0.5972,  0.7915,\n",
       "         -0.7421, -0.6814, -0.8393,  0.9335,  0.7993, -0.8127, -0.4080, -0.0598,\n",
       "          0.9637,  0.9767,  0.7052, -0.7494, -0.2626,  0.5312, -0.9498, -0.3361,\n",
       "         -0.6100,  0.9976, -0.7899, -0.9734,  0.8962, -0.9459, -0.9449, -0.9898,\n",
       "         -0.9074, -0.9418,  0.4315, -0.9988, -0.9578,  0.2997,  0.7396, -0.0212,\n",
       "         -0.8874, -0.0130, -0.8974,  0.6959,  0.9771,  0.9507, -0.0626,  0.8766,\n",
       "         -0.9842,  0.0042, -0.7187, -0.2588,  0.1822, -0.9855, -0.9792, -0.7353,\n",
       "         -0.8742,  0.9306,  0.9718, -0.8057,  0.9414, -0.9014,  0.9342, -0.7018,\n",
       "         -0.1185, -0.9616, -0.6359, -0.0465, -0.3311, -0.9915,  0.9732,  0.9610,\n",
       "         -0.9833, -0.4368,  0.5660,  0.5799, -0.9704, -0.8277,  0.7248,  0.8524,\n",
       "          0.8113, -0.3980, -0.9989, -0.8570,  0.7426,  0.8872,  0.9987, -0.8999,\n",
       "          0.9981,  0.8751,  0.6983,  0.9016,  0.8816,  0.9591,  0.1663,  0.9006,\n",
       "         -0.9199,  0.8881,  0.0518,  0.7175, -0.9871,  0.9498, -0.8318,  0.7831,\n",
       "          0.9995,  0.6859,  0.7619,  0.9927, -0.5066,  0.9887,  0.8726,  0.9654,\n",
       "          0.8217, -0.7367,  0.0934, -0.4762, -0.6698,  0.7270,  0.1587,  0.5666,\n",
       "         -0.8550,  0.1180,  0.6645,  0.2478, -0.4408, -0.6965,  0.3333,  0.9948,\n",
       "         -0.2176,  0.9426,  0.8940, -0.9989,  0.9959,  0.2941,  0.8807,  0.8014,\n",
       "         -0.8506,  0.9896,  0.9638, -0.9764,  0.5167, -0.6811, -0.9386, -0.8769,\n",
       "         -0.7650, -0.4145,  0.3419, -0.9979,  0.8459,  0.9973,  0.0237,  0.0153,\n",
       "         -0.7994, -0.0602, -0.3789, -0.3694,  0.6619, -0.9063, -0.9826,  0.3263,\n",
       "          0.8294,  0.9574, -0.8191, -0.2288,  0.9992, -0.7776, -0.9967, -0.9078,\n",
       "         -0.7850, -0.9991,  0.3621, -0.9872,  0.9347, -0.7771, -0.5664, -0.0303,\n",
       "          0.7184, -0.6969, -0.9681,  0.1889,  0.8739, -0.9846, -0.7776,  0.5552,\n",
       "          0.8168,  0.9678, -0.1052, -0.9857,  0.8491,  0.6617, -0.1828, -0.5211,\n",
       "          0.9328,  0.1137, -0.5461, -0.4530,  0.9742, -0.9775,  0.6742, -0.9327,\n",
       "          0.8839,  0.9958, -0.8622,  0.9088, -0.4997, -0.8088,  0.9087, -0.7126,\n",
       "          0.9809,  0.4448, -0.8436, -0.6790,  0.9891, -0.1512,  0.8040,  0.1358,\n",
       "         -0.9968, -0.3848, -0.9200, -0.2001,  0.9425, -0.9530, -0.9881, -0.9713,\n",
       "          0.3840, -0.1127, -0.9253, -0.7700, -0.6071,  0.2763,  0.9668,  0.8789,\n",
       "         -0.9493,  0.2155, -0.2406,  0.7252, -0.7171,  0.0406,  0.9249, -0.8697,\n",
       "         -0.3684,  0.9892, -0.6484,  0.8830, -0.7985, -0.4860,  0.9779, -0.9422,\n",
       "         -0.7906,  0.2611, -0.1642, -0.6488, -0.9306, -0.7686, -0.9895,  0.7273,\n",
       "          0.9425,  0.7314, -0.8167,  0.4904, -0.8920, -0.6889,  0.8154,  0.9175,\n",
       "         -0.8278, -0.9098, -0.3990,  0.6421, -0.8961, -0.1006,  0.5947,  0.5760,\n",
       "          0.9414,  0.8122,  0.4212, -0.5782,  0.5059, -0.9709, -0.6067, -0.5903,\n",
       "         -0.7189, -0.9499, -0.3075, -0.5469,  0.9616, -0.9275,  0.7645,  0.7841,\n",
       "          0.9805, -0.7463, -0.4891, -0.8394, -0.9430, -0.9479,  0.7162, -0.6544,\n",
       "         -0.9220,  0.6738,  0.5705, -0.5825, -0.8169, -0.2231,  0.7551, -0.1787,\n",
       "         -0.9920,  0.7533,  0.9648, -0.1550,  0.2730,  0.9011, -0.1480,  0.9476,\n",
       "          0.4797, -0.4458,  0.8991,  0.8276,  0.9777, -0.9390,  0.3159, -0.1875,\n",
       "         -0.7444, -0.2599, -0.0101, -0.9890,  0.2332, -0.2449, -0.5214, -0.2623,\n",
       "         -0.9233,  0.3046, -0.9865, -0.7688, -0.6958, -0.7850,  0.9169,  0.9700]],\n",
       "       grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=(tensor([[[[6.2043e-04, 2.6172e-03, 8.9522e-04,  ..., 1.2980e-03,\n",
       "           1.7472e-03, 9.6261e-01],\n",
       "          [3.0339e-02, 7.0712e-02, 2.1275e-02,  ..., 2.1203e-02,\n",
       "           4.5651e-02, 6.6954e-03],\n",
       "          [3.1019e-02, 2.7490e-02, 9.1975e-03,  ..., 4.5575e-02,\n",
       "           1.7051e-02, 6.8314e-03],\n",
       "          ...,\n",
       "          [4.5614e-02, 3.8275e-02, 3.3295e-02,  ..., 5.8891e-02,\n",
       "           2.1311e-02, 1.8636e-02],\n",
       "          [3.5039e-02, 1.5726e-02, 4.6151e-02,  ..., 6.7893e-02,\n",
       "           6.2155e-03, 6.7138e-03],\n",
       "          [9.1244e-01, 5.0548e-03, 1.4844e-03,  ..., 5.4512e-03,\n",
       "           4.8061e-03, 2.7211e-03]],\n",
       "\n",
       "         [[2.2416e-02, 1.3964e-02, 1.0259e-02,  ..., 8.6136e-03,\n",
       "           4.5173e-03, 7.3297e-01],\n",
       "          [1.0430e-01, 4.7057e-02, 3.1528e-01,  ..., 2.3341e-04,\n",
       "           7.2508e-03, 8.3452e-03],\n",
       "          [3.3869e-02, 4.7658e-01, 8.4863e-03,  ..., 3.8979e-04,\n",
       "           4.2075e-04, 2.7585e-02],\n",
       "          ...,\n",
       "          [2.6577e-02, 1.9967e-03, 1.3971e-03,  ..., 1.9350e-02,\n",
       "           2.8812e-02, 4.2120e-02],\n",
       "          [9.3660e-02, 8.7783e-03, 3.4070e-03,  ..., 4.0842e-01,\n",
       "           3.5635e-02, 2.4212e-01],\n",
       "          [5.5091e-03, 4.0392e-06, 1.3031e-05,  ..., 2.3731e-06,\n",
       "           7.7740e-06, 9.9445e-01]],\n",
       "\n",
       "         [[7.0329e-01, 6.5748e-03, 1.4338e-02,  ..., 1.2167e-02,\n",
       "           1.2683e-02, 1.6100e-02],\n",
       "          [7.5525e-01, 1.7563e-02, 1.0136e-02,  ..., 9.4450e-03,\n",
       "           6.5129e-03, 1.6172e-02],\n",
       "          [6.4728e-01, 2.1073e-02, 1.0803e-01,  ..., 1.3424e-02,\n",
       "           9.9957e-03, 9.1611e-03],\n",
       "          ...,\n",
       "          [1.0018e-01, 6.0616e-02, 2.2776e-02,  ..., 6.6616e-02,\n",
       "           5.7477e-03, 6.2395e-03],\n",
       "          [5.5635e-02, 4.8653e-02, 2.6951e-02,  ..., 8.8789e-03,\n",
       "           2.4144e-02, 5.5895e-03],\n",
       "          [3.4319e-01, 2.7126e-02, 8.5846e-03,  ..., 9.9326e-03,\n",
       "           5.6810e-03, 2.6816e-03]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[9.6312e-01, 7.2885e-04, 1.2221e-03,  ..., 1.2074e-03,\n",
       "           1.6908e-03, 1.0999e-02],\n",
       "          [9.0140e-02, 6.1300e-02, 2.5058e-02,  ..., 1.2649e-02,\n",
       "           9.2214e-03, 3.0042e-02],\n",
       "          [1.2199e-01, 4.8641e-02, 1.7830e-02,  ..., 6.5411e-02,\n",
       "           3.0485e-02, 4.9056e-02],\n",
       "          ...,\n",
       "          [1.3066e-01, 3.3334e-02, 7.7133e-02,  ..., 8.7384e-02,\n",
       "           3.4283e-02, 4.4496e-02],\n",
       "          [1.0789e-01, 1.4525e-02, 3.5075e-02,  ..., 2.1042e-02,\n",
       "           1.0329e-02, 2.9344e-02],\n",
       "          [7.9892e-01, 1.6379e-03, 2.6289e-03,  ..., 3.9227e-03,\n",
       "           1.8739e-03, 1.4852e-01]],\n",
       "\n",
       "         [[9.4099e-01, 2.3810e-03, 1.8997e-03,  ..., 2.9731e-03,\n",
       "           1.4038e-03, 5.0936e-03],\n",
       "          [1.3701e-02, 3.0335e-02, 2.8639e-01,  ..., 2.4403e-03,\n",
       "           2.1990e-03, 2.3828e-02],\n",
       "          [7.1634e-02, 2.0541e-01, 6.5671e-02,  ..., 1.5891e-02,\n",
       "           2.7714e-03, 1.5762e-02],\n",
       "          ...,\n",
       "          [2.3833e-02, 1.2438e-03, 1.8269e-02,  ..., 2.7355e-02,\n",
       "           1.0931e-01, 1.7845e-01],\n",
       "          [5.0432e-03, 8.6806e-03, 7.1158e-03,  ..., 5.4427e-01,\n",
       "           1.2017e-02, 1.6043e-01],\n",
       "          [8.8272e-01, 2.8675e-04, 5.9453e-04,  ..., 1.3623e-02,\n",
       "           2.7750e-03, 9.2067e-02]],\n",
       "\n",
       "         [[9.3131e-01, 3.0844e-03, 1.1559e-03,  ..., 2.7699e-03,\n",
       "           3.3020e-03, 3.5952e-03],\n",
       "          [5.6876e-02, 3.4772e-02, 2.1383e-01,  ..., 6.0731e-03,\n",
       "           7.2735e-03, 9.6313e-03],\n",
       "          [3.8160e-02, 3.7636e-01, 2.8223e-02,  ..., 9.0513e-03,\n",
       "           5.9038e-03, 8.5072e-03],\n",
       "          ...,\n",
       "          [3.8915e-02, 2.2808e-02, 1.2532e-02,  ..., 3.4947e-02,\n",
       "           9.7645e-02, 1.3834e-01],\n",
       "          [4.0390e-02, 2.9579e-02, 1.4175e-02,  ..., 7.5658e-02,\n",
       "           2.7254e-02, 3.1304e-01],\n",
       "          [7.0269e-01, 1.1741e-03, 1.4932e-03,  ..., 2.3990e-02,\n",
       "           5.6134e-02, 1.8552e-01]]]], grad_fn=<SoftmaxBackward0>), tensor([[[[6.6329e-01, 1.7640e-02, 1.2812e-02,  ..., 1.1879e-02,\n",
       "           1.1829e-02, 5.5437e-02],\n",
       "          [6.7246e-01, 2.4664e-03, 3.2126e-03,  ..., 2.1479e-05,\n",
       "           1.6853e-01, 6.0165e-04],\n",
       "          [2.2273e-02, 9.6985e-01, 1.5423e-04,  ..., 1.7053e-05,\n",
       "           1.0052e-06, 1.0169e-03],\n",
       "          ...,\n",
       "          [5.3531e-01, 6.0274e-06, 5.8463e-05,  ..., 4.0152e-03,\n",
       "           1.7713e-01, 7.9418e-03],\n",
       "          [2.5557e-02, 4.1419e-05, 2.6535e-04,  ..., 9.4917e-01,\n",
       "           6.7660e-03, 5.3351e-03],\n",
       "          [9.8904e-01, 1.4075e-06, 3.6009e-04,  ..., 8.3621e-05,\n",
       "           7.9781e-03, 1.3527e-03]],\n",
       "\n",
       "         [[9.3014e-02, 3.1621e-02, 3.7763e-02,  ..., 3.8536e-02,\n",
       "           4.0394e-02, 4.4288e-02],\n",
       "          [1.2937e-01, 3.6423e-04, 2.4618e-02,  ..., 9.9059e-03,\n",
       "           4.0750e-02, 1.1152e-02],\n",
       "          [6.2737e-02, 9.2560e-02, 1.9188e-03,  ..., 2.7533e-03,\n",
       "           2.7068e-02, 1.0499e-02],\n",
       "          ...,\n",
       "          [1.4025e-01, 1.5132e-03, 2.7283e-02,  ..., 2.8575e-04,\n",
       "           5.1286e-02, 1.7805e-02],\n",
       "          [1.1686e-01, 5.5110e-02, 5.7476e-02,  ..., 8.3319e-02,\n",
       "           2.0624e-03, 2.4074e-02],\n",
       "          [3.9093e-01, 8.8152e-03, 7.0994e-03,  ..., 1.0200e-02,\n",
       "           1.7788e-02, 3.1392e-01]],\n",
       "\n",
       "         [[8.9092e-01, 5.4951e-03, 1.1209e-03,  ..., 4.9597e-03,\n",
       "           5.6596e-03, 2.2012e-02],\n",
       "          [1.1515e-01, 1.2898e-01, 1.1938e-02,  ..., 9.9467e-04,\n",
       "           1.9644e-03, 1.4470e-02],\n",
       "          [1.3460e-01, 1.2368e-01, 6.4026e-02,  ..., 1.1537e-02,\n",
       "           4.1494e-03, 5.8104e-02],\n",
       "          ...,\n",
       "          [2.7736e-02, 1.9261e-03, 2.5284e-03,  ..., 3.6065e-02,\n",
       "           7.7169e-03, 3.6336e-02],\n",
       "          [1.2819e-01, 7.4466e-03, 1.2018e-02,  ..., 2.9157e-01,\n",
       "           7.2868e-02, 1.9031e-02],\n",
       "          [9.4987e-01, 1.7236e-03, 1.9885e-04,  ..., 3.4296e-03,\n",
       "           7.9175e-03, 1.1335e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[8.9649e-01, 1.1936e-03, 4.3939e-03,  ..., 4.7052e-03,\n",
       "           6.6763e-03, 1.2835e-02],\n",
       "          [2.5393e-01, 2.4125e-02, 4.8540e-02,  ..., 9.9256e-04,\n",
       "           9.7305e-03, 1.3744e-02],\n",
       "          [1.0491e-01, 2.7079e-03, 5.5384e-02,  ..., 4.4226e-03,\n",
       "           6.2976e-03, 8.3545e-03],\n",
       "          ...,\n",
       "          [7.4676e-01, 1.6776e-04, 9.9512e-04,  ..., 1.4243e-01,\n",
       "           3.7613e-02, 4.4936e-02],\n",
       "          [6.0649e-01, 1.6570e-03, 7.2138e-03,  ..., 1.9620e-02,\n",
       "           2.4488e-01, 5.7122e-02],\n",
       "          [9.9876e-01, 2.4878e-06, 1.3381e-05,  ..., 5.6412e-05,\n",
       "           1.6168e-04, 4.0134e-04]],\n",
       "\n",
       "         [[7.1510e-01, 1.5662e-02, 1.4217e-02,  ..., 9.5790e-03,\n",
       "           1.0153e-02, 1.7487e-02],\n",
       "          [2.9815e-01, 3.2052e-03, 7.2472e-02,  ..., 6.9685e-04,\n",
       "           1.0322e-02, 2.2555e-02],\n",
       "          [1.2102e-01, 1.4133e-02, 2.8134e-02,  ..., 1.3583e-03,\n",
       "           1.6044e-02, 3.3545e-02],\n",
       "          ...,\n",
       "          [2.4329e-01, 1.0938e-01, 7.9434e-03,  ..., 1.0165e-02,\n",
       "           3.1731e-03, 1.1666e-02],\n",
       "          [6.7250e-01, 4.6665e-03, 1.2339e-02,  ..., 4.9308e-03,\n",
       "           6.4865e-04, 6.2777e-03],\n",
       "          [1.5014e-01, 3.4178e-02, 2.7593e-02,  ..., 1.0042e-02,\n",
       "           1.4683e-03, 4.3514e-01]],\n",
       "\n",
       "         [[9.3780e-01, 1.2723e-03, 1.5351e-03,  ..., 4.3230e-03,\n",
       "           1.8163e-03, 4.0603e-03],\n",
       "          [2.5917e-01, 9.4075e-03, 1.0681e-02,  ..., 5.7923e-02,\n",
       "           1.1908e-02, 1.0166e-02],\n",
       "          [1.0720e-01, 1.8852e-02, 1.0820e-02,  ..., 8.8494e-03,\n",
       "           8.7582e-02, 9.1686e-03],\n",
       "          ...,\n",
       "          [1.7637e-01, 1.9694e-03, 7.0992e-02,  ..., 6.5048e-02,\n",
       "           1.0321e-01, 1.0604e-03],\n",
       "          [4.0605e-01, 7.9048e-03, 6.1698e-02,  ..., 2.7248e-02,\n",
       "           2.8466e-02, 6.9575e-03],\n",
       "          [9.6428e-01, 4.6604e-04, 1.1487e-03,  ..., 3.9847e-03,\n",
       "           1.3112e-03, 5.5353e-03]]]], grad_fn=<SoftmaxBackward0>), tensor([[[[8.0831e-01, 1.8235e-03, 2.7445e-03,  ..., 1.6598e-03,\n",
       "           8.7992e-04, 1.5462e-01],\n",
       "          [5.6487e-01, 4.9350e-03, 1.0090e-02,  ..., 3.4771e-03,\n",
       "           4.0974e-03, 2.4754e-01],\n",
       "          [7.9231e-01, 2.0584e-03, 3.8638e-03,  ..., 4.5109e-03,\n",
       "           6.1884e-02, 8.4380e-02],\n",
       "          ...,\n",
       "          [7.4473e-01, 7.5445e-04, 1.0168e-03,  ..., 1.1114e-02,\n",
       "           2.3914e-02, 1.4635e-01],\n",
       "          [2.1072e-01, 5.9785e-02, 4.0983e-03,  ..., 4.3151e-03,\n",
       "           2.1776e-02, 4.5887e-02],\n",
       "          [9.4511e-01, 2.1644e-04, 4.9935e-04,  ..., 2.2283e-04,\n",
       "           1.2893e-04, 4.7220e-02]],\n",
       "\n",
       "         [[9.0213e-01, 3.8508e-04, 1.3124e-03,  ..., 4.7000e-03,\n",
       "           1.7957e-03, 5.7440e-02],\n",
       "          [9.3268e-03, 2.4445e-04, 9.8201e-01,  ..., 7.8083e-09,\n",
       "           8.5057e-06, 1.4193e-03],\n",
       "          [8.3223e-01, 2.6613e-03, 5.3720e-03,  ..., 5.9653e-05,\n",
       "           3.0533e-05, 1.3603e-01],\n",
       "          ...,\n",
       "          [8.4790e-04, 6.6418e-09, 3.1311e-06,  ..., 6.2174e-06,\n",
       "           9.9809e-01, 3.0497e-04],\n",
       "          [8.8543e-01, 1.1890e-04, 5.5810e-07,  ..., 5.0336e-04,\n",
       "           1.8787e-02, 9.2663e-02],\n",
       "          [8.3908e-01, 3.6154e-04, 2.6428e-03,  ..., 1.5511e-02,\n",
       "           4.8238e-03, 9.7614e-02]],\n",
       "\n",
       "         [[3.5117e-01, 1.7762e-04, 3.0045e-04,  ..., 4.2031e-04,\n",
       "           1.0959e-04, 6.4349e-01],\n",
       "          [3.6422e-01, 8.2706e-03, 6.3380e-02,  ..., 3.3880e-02,\n",
       "           2.6516e-02, 4.0640e-02],\n",
       "          [4.2521e-01, 1.2574e-02, 6.1863e-02,  ..., 3.9583e-02,\n",
       "           9.5018e-03, 1.1662e-01],\n",
       "          ...,\n",
       "          [8.9189e-02, 7.6786e-03, 9.5673e-03,  ..., 1.8992e-02,\n",
       "           2.7243e-02, 8.9961e-03],\n",
       "          [4.0045e-01, 6.9825e-03, 5.1901e-03,  ..., 2.9682e-01,\n",
       "           7.6082e-03, 1.1309e-01],\n",
       "          [8.1407e-01, 8.5547e-05, 5.5127e-05,  ..., 1.8120e-04,\n",
       "           9.1654e-05, 1.8384e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[8.6728e-01, 3.6012e-03, 2.7419e-03,  ..., 6.2824e-03,\n",
       "           3.3047e-03, 5.1070e-02],\n",
       "          [2.1592e-01, 1.6838e-02, 2.0944e-01,  ..., 1.0679e-03,\n",
       "           4.4516e-04, 6.3860e-02],\n",
       "          [2.6566e-01, 3.4785e-03, 3.8946e-02,  ..., 1.6317e-04,\n",
       "           5.2134e-05, 1.9443e-02],\n",
       "          ...,\n",
       "          [6.2889e-01, 2.1145e-04, 9.5697e-05,  ..., 6.1054e-02,\n",
       "           9.0956e-02, 1.8910e-01],\n",
       "          [5.7484e-01, 1.4489e-04, 2.2115e-03,  ..., 6.1297e-02,\n",
       "           1.8168e-01, 1.5210e-01],\n",
       "          [9.5077e-01, 1.0231e-03, 5.8659e-04,  ..., 1.8688e-03,\n",
       "           1.4224e-03, 3.1118e-02]],\n",
       "\n",
       "         [[9.0290e-01, 3.4559e-03, 2.3501e-03,  ..., 2.6846e-03,\n",
       "           1.0271e-03, 3.9019e-02],\n",
       "          [7.6786e-01, 2.6809e-02, 2.2436e-02,  ..., 2.0738e-03,\n",
       "           7.3650e-05, 1.5512e-01],\n",
       "          [5.6677e-01, 5.8843e-02, 1.2494e-01,  ..., 2.1111e-04,\n",
       "           1.3643e-03, 2.2971e-01],\n",
       "          ...,\n",
       "          [4.3958e-02, 4.3619e-05, 5.9364e-05,  ..., 2.9694e-02,\n",
       "           9.7340e-03, 4.1084e-03],\n",
       "          [2.0713e-02, 6.5693e-05, 9.1432e-06,  ..., 5.8464e-02,\n",
       "           2.6354e-02, 4.6226e-03],\n",
       "          [9.4525e-01, 1.8064e-03, 1.1954e-03,  ..., 3.3248e-03,\n",
       "           7.9168e-04, 3.3982e-02]],\n",
       "\n",
       "         [[8.9412e-01, 2.0430e-03, 1.6421e-03,  ..., 1.5256e-03,\n",
       "           2.6374e-03, 5.4082e-02],\n",
       "          [1.3520e-01, 1.0320e-04, 8.4826e-01,  ..., 5.8167e-05,\n",
       "           4.5769e-05, 7.6724e-03],\n",
       "          [7.6729e-01, 6.5362e-03, 2.0645e-03,  ..., 1.4726e-05,\n",
       "           5.4184e-05, 1.4391e-01],\n",
       "          ...,\n",
       "          [3.1136e-01, 3.5509e-06, 3.3739e-05,  ..., 2.9110e-03,\n",
       "           6.4564e-01, 1.2541e-02],\n",
       "          [7.9280e-01, 7.2669e-04, 6.9169e-07,  ..., 9.0299e-02,\n",
       "           8.8044e-04, 1.0067e-01],\n",
       "          [3.0698e-01, 6.5609e-05, 6.6571e-05,  ..., 1.5759e-05,\n",
       "           2.4776e-04, 6.8908e-01]]]], grad_fn=<SoftmaxBackward0>), tensor([[[[2.3658e-02, 1.1895e-03, 5.1595e-04,  ..., 7.0314e-03,\n",
       "           5.9926e-03, 8.9961e-01],\n",
       "          [7.6009e-02, 1.4463e-02, 2.0403e-02,  ..., 3.5591e-02,\n",
       "           4.3540e-03, 6.0552e-01],\n",
       "          [8.7942e-02, 3.3397e-02, 1.3531e-02,  ..., 5.1168e-02,\n",
       "           5.8428e-03, 2.7818e-01],\n",
       "          ...,\n",
       "          [2.6985e-02, 2.8487e-03, 1.3331e-03,  ..., 2.0673e-01,\n",
       "           7.6888e-02, 2.8025e-01],\n",
       "          [3.8230e-03, 3.3976e-04, 1.0208e-03,  ..., 8.2117e-01,\n",
       "           8.7119e-03, 3.2510e-02],\n",
       "          [2.0065e-03, 1.2065e-04, 4.1007e-05,  ..., 9.7033e-05,\n",
       "           1.6073e-04, 9.9522e-01]],\n",
       "\n",
       "         [[4.3666e-02, 4.0174e-02, 4.4595e-02,  ..., 3.2392e-02,\n",
       "           1.8135e-02, 5.1256e-02],\n",
       "          [1.4449e-01, 1.6694e-02, 8.4846e-02,  ..., 1.0140e-02,\n",
       "           2.4841e-03, 3.0704e-01],\n",
       "          [8.6134e-02, 4.2086e-02, 8.2595e-02,  ..., 2.5394e-02,\n",
       "           4.4377e-03, 4.6236e-01],\n",
       "          ...,\n",
       "          [2.5759e-01, 5.1838e-03, 1.1481e-03,  ..., 5.4970e-03,\n",
       "           1.7202e-02, 6.2935e-01],\n",
       "          [8.5317e-02, 9.9431e-03, 1.4367e-02,  ..., 3.9523e-02,\n",
       "           1.0119e-02, 6.2677e-01],\n",
       "          [5.8604e-02, 2.1287e-03, 1.3905e-03,  ..., 4.4761e-03,\n",
       "           3.6683e-03, 8.8541e-01]],\n",
       "\n",
       "         [[3.0860e-01, 2.8595e-02, 1.8422e-02,  ..., 6.2770e-03,\n",
       "           1.6254e-02, 1.7554e-01],\n",
       "          [9.0643e-02, 2.9619e-01, 1.1429e-02,  ..., 2.9578e-04,\n",
       "           2.5673e-04, 6.1081e-02],\n",
       "          [1.6602e-01, 2.0927e-02, 1.8796e-01,  ..., 1.1771e-03,\n",
       "           1.9108e-03, 1.9091e-01],\n",
       "          ...,\n",
       "          [1.7292e-02, 1.1694e-04, 3.6556e-04,  ..., 9.4534e-01,\n",
       "           8.7738e-03, 1.2380e-02],\n",
       "          [3.2099e-01, 6.5404e-04, 7.5248e-04,  ..., 9.1977e-02,\n",
       "           3.4515e-01, 1.6928e-01],\n",
       "          [2.7773e-01, 2.8617e-02, 1.6107e-02,  ..., 1.9310e-02,\n",
       "           1.8959e-02, 1.7396e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[4.1719e-02, 6.4526e-03, 3.1056e-03,  ..., 2.3292e-03,\n",
       "           1.6298e-03, 8.8241e-01],\n",
       "          [7.4004e-02, 5.0343e-03, 3.7614e-03,  ..., 5.7447e-04,\n",
       "           8.7548e-04, 8.9127e-01],\n",
       "          [2.3519e-02, 2.3507e-02, 3.1751e-03,  ..., 2.2751e-04,\n",
       "           5.1726e-04, 9.1603e-01],\n",
       "          ...,\n",
       "          [7.4807e-02, 1.0809e-03, 8.8235e-04,  ..., 5.4432e-02,\n",
       "           5.2578e-02, 4.9772e-01],\n",
       "          [5.8372e-02, 1.2918e-03, 6.0847e-04,  ..., 2.0520e-01,\n",
       "           3.3914e-02, 2.0314e-01],\n",
       "          [1.5084e-02, 4.2142e-03, 2.1604e-03,  ..., 9.7067e-04,\n",
       "           1.2400e-03, 9.5341e-01]],\n",
       "\n",
       "         [[5.1748e-02, 2.7503e-03, 3.8341e-04,  ..., 6.7087e-04,\n",
       "           2.4163e-04, 9.3118e-01],\n",
       "          [2.5524e-01, 2.3063e-01, 2.6796e-04,  ..., 1.2667e-04,\n",
       "           1.6614e-04, 1.7472e-01],\n",
       "          [2.3388e-01, 1.5523e-03, 1.4761e-01,  ..., 1.3172e-03,\n",
       "           1.4395e-04, 5.8371e-02],\n",
       "          ...,\n",
       "          [1.3738e-01, 3.0981e-04, 5.7181e-04,  ..., 2.2188e-01,\n",
       "           6.7440e-04, 6.1720e-01],\n",
       "          [1.7024e-01, 2.5209e-04, 4.2492e-04,  ..., 1.0604e-03,\n",
       "           5.6240e-02, 7.5999e-01],\n",
       "          [2.3265e-02, 7.4737e-04, 3.8097e-04,  ..., 2.5787e-04,\n",
       "           1.3704e-04, 9.6804e-01]],\n",
       "\n",
       "         [[6.0364e-02, 6.3705e-04, 3.5644e-04,  ..., 2.0235e-03,\n",
       "           5.0233e-03, 8.9706e-01],\n",
       "          [1.2420e-01, 4.7718e-03, 9.5098e-02,  ..., 1.3356e-03,\n",
       "           4.5575e-04, 2.8307e-01],\n",
       "          [5.7984e-02, 2.6141e-02, 1.9218e-02,  ..., 6.6951e-04,\n",
       "           5.8840e-04, 4.0189e-01],\n",
       "          ...,\n",
       "          [6.2324e-02, 3.6032e-04, 1.1160e-04,  ..., 2.7151e-02,\n",
       "           7.3735e-02, 7.9369e-01],\n",
       "          [5.5475e-02, 2.0504e-04, 4.6138e-05,  ..., 4.3210e-02,\n",
       "           4.8360e-02, 7.7662e-01],\n",
       "          [2.7740e-02, 6.8115e-04, 3.3643e-04,  ..., 1.0921e-03,\n",
       "           4.5631e-03, 9.4205e-01]]]], grad_fn=<SoftmaxBackward0>), tensor([[[[1.4631e-02, 1.7243e-02, 1.9244e-02,  ..., 5.1861e-02,\n",
       "           1.4936e-02, 1.3237e-01],\n",
       "          [6.6042e-03, 1.6682e-02, 3.9733e-02,  ..., 2.5088e-02,\n",
       "           9.1897e-03, 2.1376e-01],\n",
       "          [6.6183e-03, 1.1713e-02, 5.9939e-02,  ..., 2.1545e-02,\n",
       "           9.0719e-03, 5.7113e-02],\n",
       "          ...,\n",
       "          [1.2027e-02, 1.3257e-02, 5.8894e-03,  ..., 1.9081e-01,\n",
       "           2.2267e-02, 2.0514e-01],\n",
       "          [1.6456e-02, 1.7477e-02, 1.7056e-02,  ..., 1.2066e-01,\n",
       "           2.3520e-02, 1.4963e-01],\n",
       "          [1.3503e-02, 3.4820e-04, 2.7581e-04,  ..., 7.9407e-04,\n",
       "           2.2699e-04, 9.7616e-01]],\n",
       "\n",
       "         [[1.4941e-01, 5.8787e-02, 6.6495e-02,  ..., 6.4897e-03,\n",
       "           3.7020e-03, 3.1043e-01],\n",
       "          [1.7319e-01, 2.2059e-02, 3.5831e-02,  ..., 9.7068e-04,\n",
       "           2.7191e-04, 3.2602e-01],\n",
       "          [1.5712e-01, 8.9094e-03, 7.1288e-02,  ..., 1.6078e-03,\n",
       "           4.4145e-03, 1.1291e-01],\n",
       "          ...,\n",
       "          [8.6086e-02, 2.0848e-03, 4.5829e-03,  ..., 2.0507e-03,\n",
       "           6.1298e-03, 6.1917e-01],\n",
       "          [1.1531e-01, 1.6568e-03, 1.3921e-02,  ..., 6.5531e-03,\n",
       "           1.5362e-03, 7.1353e-01],\n",
       "          [8.2575e-03, 5.9298e-04, 7.4363e-04,  ..., 2.1062e-04,\n",
       "           8.6198e-04, 9.6536e-01]],\n",
       "\n",
       "         [[5.7086e-02, 4.2041e-03, 6.8961e-03,  ..., 1.8197e-03,\n",
       "           2.7930e-03, 8.1644e-01],\n",
       "          [1.5210e-02, 2.2192e-01, 3.7289e-07,  ..., 1.5049e-08,\n",
       "           1.0400e-07, 4.0554e-02],\n",
       "          [2.1651e-03, 8.9954e-08, 1.0540e-01,  ..., 1.3573e-06,\n",
       "           9.2674e-09, 9.9292e-03],\n",
       "          ...,\n",
       "          [5.2480e-03, 5.8179e-08, 7.6552e-07,  ..., 9.3226e-01,\n",
       "           3.3234e-07, 6.2372e-02],\n",
       "          [5.1285e-03, 1.4696e-06, 1.1614e-07,  ..., 2.4165e-06,\n",
       "           1.1399e-02, 9.8340e-01],\n",
       "          [9.6878e-03, 1.6556e-04, 4.2364e-04,  ..., 2.5440e-04,\n",
       "           1.4874e-04, 9.8447e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[6.9146e-02, 2.3288e-02, 3.4089e-02,  ..., 6.9838e-02,\n",
       "           6.8676e-02, 9.6205e-02],\n",
       "          [1.3298e-01, 2.4965e-02, 4.2307e-02,  ..., 3.9390e-02,\n",
       "           6.8578e-02, 1.4883e-01],\n",
       "          [5.9645e-02, 5.1899e-02, 1.4550e-01,  ..., 1.5796e-02,\n",
       "           1.5774e-02, 7.0845e-02],\n",
       "          ...,\n",
       "          [2.7684e-02, 9.3272e-04, 5.7410e-03,  ..., 1.8726e-01,\n",
       "           9.4526e-02, 2.6427e-02],\n",
       "          [4.5425e-03, 5.5359e-05, 2.2066e-03,  ..., 1.3068e-01,\n",
       "           1.7890e-02, 9.0412e-03],\n",
       "          [1.2656e-01, 3.2105e-02, 2.1369e-02,  ..., 4.2057e-02,\n",
       "           2.6446e-02, 1.1006e-01]],\n",
       "\n",
       "         [[6.7743e-03, 2.8035e-03, 1.6104e-02,  ..., 4.0411e-03,\n",
       "           2.2914e-03, 9.0156e-01],\n",
       "          [5.8599e-02, 5.7523e-02, 2.7653e-02,  ..., 1.8124e-04,\n",
       "           3.9811e-04, 7.0371e-01],\n",
       "          [3.0381e-02, 6.7800e-01, 1.4334e-02,  ..., 6.6568e-04,\n",
       "           9.8762e-05, 1.3672e-01],\n",
       "          ...,\n",
       "          [2.9473e-02, 6.9419e-04, 4.0090e-03,  ..., 1.0780e-01,\n",
       "           5.2319e-03, 3.3535e-01],\n",
       "          [2.6800e-02, 3.7377e-04, 8.2620e-03,  ..., 6.9927e-01,\n",
       "           6.1356e-04, 5.2542e-02],\n",
       "          [3.8032e-04, 2.3016e-04, 2.0021e-03,  ..., 1.4384e-03,\n",
       "           2.8665e-04, 9.8868e-01]],\n",
       "\n",
       "         [[4.5100e-02, 4.3134e-03, 2.1123e-02,  ..., 3.3023e-02,\n",
       "           2.9910e-02, 4.7824e-01],\n",
       "          [3.9468e-02, 6.4091e-03, 7.4783e-02,  ..., 3.4016e-03,\n",
       "           1.6568e-03, 6.0009e-01],\n",
       "          [6.9019e-02, 6.6289e-03, 4.0443e-04,  ..., 1.9323e-02,\n",
       "           1.1302e-02, 5.3101e-01],\n",
       "          ...,\n",
       "          [8.0087e-02, 2.8279e-03, 6.1872e-03,  ..., 2.4567e-02,\n",
       "           6.0752e-02, 5.0781e-01],\n",
       "          [9.2470e-02, 4.8492e-03, 2.1305e-02,  ..., 1.5849e-02,\n",
       "           2.8556e-03, 5.1287e-01],\n",
       "          [5.8188e-03, 7.2224e-04, 8.7313e-04,  ..., 1.5217e-03,\n",
       "           1.0980e-03, 9.7044e-01]]]], grad_fn=<SoftmaxBackward0>), tensor([[[[5.9840e-04, 3.5502e-03, 4.2247e-03,  ..., 3.3452e-03,\n",
       "           2.8558e-03, 8.1640e-01],\n",
       "          [1.2674e-01, 3.8730e-02, 2.0781e-02,  ..., 2.2430e-06,\n",
       "           6.2520e-06, 7.2488e-01],\n",
       "          [1.3198e-02, 3.1386e-03, 2.4652e-01,  ..., 3.5819e-06,\n",
       "           2.7215e-06, 4.1193e-01],\n",
       "          ...,\n",
       "          [2.2590e-02, 9.0798e-07, 6.1761e-07,  ..., 9.2709e-02,\n",
       "           1.6943e-02, 8.6220e-01],\n",
       "          [7.7577e-03, 3.0116e-06, 1.4370e-06,  ..., 3.9342e-02,\n",
       "           1.8436e-02, 9.2992e-01],\n",
       "          [2.6119e-04, 7.5227e-03, 4.2259e-03,  ..., 1.1540e-03,\n",
       "           4.0594e-03, 9.0621e-01]],\n",
       "\n",
       "         [[2.7470e-02, 2.4587e-02, 8.8286e-02,  ..., 7.3745e-03,\n",
       "           7.4536e-03, 5.5476e-01],\n",
       "          [6.6129e-02, 1.7789e-02, 5.4621e-02,  ..., 2.1748e-03,\n",
       "           2.9996e-03, 5.9548e-01],\n",
       "          [5.2841e-02, 6.4949e-03, 1.9282e-03,  ..., 1.4337e-02,\n",
       "           3.2880e-02, 4.6686e-01],\n",
       "          ...,\n",
       "          [3.6972e-02, 1.0846e-03, 5.7824e-03,  ..., 1.6402e-02,\n",
       "           1.6305e-02, 2.1221e-01],\n",
       "          [3.1829e-02, 6.3175e-04, 7.2537e-03,  ..., 1.7615e-02,\n",
       "           1.7892e-03, 2.2537e-01],\n",
       "          [1.1638e-02, 6.7524e-03, 7.2768e-03,  ..., 7.1174e-03,\n",
       "           1.0184e-02, 8.0182e-01]],\n",
       "\n",
       "         [[1.0208e-02, 7.5338e-03, 1.7744e-01,  ..., 5.3005e-03,\n",
       "           7.6135e-04, 6.0231e-02],\n",
       "          [1.1207e-02, 1.6643e-02, 1.4885e-01,  ..., 3.5948e-03,\n",
       "           3.0560e-03, 5.0240e-01],\n",
       "          [3.7982e-02, 1.6627e-02, 2.5628e-01,  ..., 4.3024e-03,\n",
       "           2.1069e-03, 1.0442e-01],\n",
       "          ...,\n",
       "          [6.5100e-02, 3.5933e-04, 8.9296e-04,  ..., 2.1306e-01,\n",
       "           5.1197e-02, 3.6047e-01],\n",
       "          [2.3430e-02, 4.2829e-05, 6.9621e-04,  ..., 9.3204e-02,\n",
       "           3.5562e-02, 6.2800e-01],\n",
       "          [1.3809e-04, 3.5410e-05, 2.9335e-04,  ..., 6.3936e-05,\n",
       "           4.0745e-05, 9.9825e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[9.4845e-03, 9.7111e-02, 4.5880e-02,  ..., 2.6095e-03,\n",
       "           4.7653e-03, 5.4422e-01],\n",
       "          [7.3126e-03, 1.6048e-02, 5.3502e-02,  ..., 3.4744e-03,\n",
       "           2.8495e-03, 6.2102e-01],\n",
       "          [1.6231e-02, 3.7238e-03, 1.2326e-02,  ..., 5.9328e-03,\n",
       "           6.0624e-03, 8.0901e-01],\n",
       "          ...,\n",
       "          [1.8626e-02, 9.0248e-04, 8.4568e-04,  ..., 1.2929e-01,\n",
       "           7.5244e-02, 5.8028e-01],\n",
       "          [9.8710e-03, 4.8922e-04, 1.1991e-03,  ..., 3.5279e-01,\n",
       "           2.2640e-01, 2.4789e-01],\n",
       "          [2.2394e-03, 3.7561e-03, 4.8514e-03,  ..., 3.0439e-03,\n",
       "           3.1816e-03, 9.2997e-01]],\n",
       "\n",
       "         [[8.1805e-03, 1.5032e-02, 9.7996e-03,  ..., 2.8127e-03,\n",
       "           4.7042e-03, 8.7039e-01],\n",
       "          [2.7240e-02, 8.4523e-03, 5.6884e-01,  ..., 4.3703e-06,\n",
       "           1.0207e-06, 3.4801e-01],\n",
       "          [9.9825e-03, 8.1005e-03, 1.0225e-02,  ..., 6.3525e-05,\n",
       "           7.3927e-06, 7.6862e-01],\n",
       "          ...,\n",
       "          [3.5732e-02, 1.3537e-06, 6.9209e-06,  ..., 1.7562e-02,\n",
       "           1.1470e-01, 8.1798e-01],\n",
       "          [5.6754e-03, 4.9283e-05, 2.6605e-06,  ..., 9.3322e-02,\n",
       "           1.5093e-02, 8.7524e-01],\n",
       "          [3.0710e-03, 4.9851e-03, 8.5110e-03,  ..., 3.2954e-03,\n",
       "           7.0733e-03, 9.1506e-01]],\n",
       "\n",
       "         [[6.6906e-03, 1.5690e-03, 1.8862e-03,  ..., 5.0830e-03,\n",
       "           1.0620e-02, 8.9985e-01],\n",
       "          [2.1224e-02, 1.3664e-02, 5.1196e-03,  ..., 2.4808e-06,\n",
       "           3.6923e-05, 8.8052e-01],\n",
       "          [2.7134e-03, 3.3071e-01, 7.1013e-04,  ..., 2.8353e-06,\n",
       "           3.6637e-06, 1.7916e-02],\n",
       "          ...,\n",
       "          [1.3853e-03, 4.2380e-06, 1.3384e-04,  ..., 1.0067e-03,\n",
       "           1.0354e-02, 9.2606e-01],\n",
       "          [7.5433e-03, 7.9824e-07, 1.5144e-06,  ..., 9.2706e-01,\n",
       "           3.9722e-03, 5.8290e-02],\n",
       "          [5.3829e-03, 1.2703e-03, 6.5499e-03,  ..., 3.1825e-03,\n",
       "           6.3052e-03, 8.9372e-01]]]], grad_fn=<SoftmaxBackward0>), tensor([[[[1.5899e-01, 1.1176e-01, 5.2103e-02,  ..., 6.2255e-04,\n",
       "           1.0456e-03, 4.6157e-01],\n",
       "          [2.4216e-02, 2.6766e-03, 2.0704e-02,  ..., 6.6445e-04,\n",
       "           2.2440e-03, 3.3055e-01],\n",
       "          [8.8109e-02, 5.3567e-03, 4.4959e-02,  ..., 5.8913e-04,\n",
       "           6.3464e-04, 2.6325e-01],\n",
       "          ...,\n",
       "          [2.6862e-01, 2.2396e-04, 2.5838e-04,  ..., 2.4875e-02,\n",
       "           1.4415e-02, 6.5411e-01],\n",
       "          [3.3405e-01, 3.7108e-04, 2.9438e-04,  ..., 3.6482e-02,\n",
       "           5.8368e-03, 5.8319e-01],\n",
       "          [9.1375e-03, 1.3766e-03, 1.0656e-03,  ..., 5.6617e-03,\n",
       "           3.8905e-03, 9.0916e-01]],\n",
       "\n",
       "         [[3.9425e-03, 7.7628e-03, 6.9310e-03,  ..., 9.8601e-03,\n",
       "           8.1358e-03, 9.0716e-01],\n",
       "          [7.4877e-02, 8.7189e-03, 6.1056e-03,  ..., 5.1097e-05,\n",
       "           6.3694e-05, 9.0027e-01],\n",
       "          [2.0288e-02, 4.2643e-03, 3.0804e-03,  ..., 9.4519e-06,\n",
       "           3.1535e-05, 9.6095e-01],\n",
       "          ...,\n",
       "          [1.4198e-03, 4.3954e-06, 1.6681e-05,  ..., 9.5038e-03,\n",
       "           1.3029e-02, 7.6421e-02],\n",
       "          [4.0231e-04, 4.1516e-06, 1.1579e-05,  ..., 2.8060e-03,\n",
       "           6.5707e-03, 7.6627e-02],\n",
       "          [7.0443e-04, 6.1630e-04, 4.5210e-04,  ..., 2.1236e-03,\n",
       "           2.3955e-03, 9.7954e-01]],\n",
       "\n",
       "         [[7.0658e-03, 4.8714e-03, 4.4122e-03,  ..., 5.2254e-04,\n",
       "           1.6960e-03, 9.7537e-01],\n",
       "          [1.4528e-02, 6.5990e-03, 9.1362e-02,  ..., 1.7633e-07,\n",
       "           4.7345e-06, 8.8249e-01],\n",
       "          [2.1075e-02, 2.2024e-02, 9.6179e-03,  ..., 3.0351e-06,\n",
       "           4.3412e-06, 9.2226e-01],\n",
       "          ...,\n",
       "          [3.5994e-03, 5.7992e-08, 2.5817e-06,  ..., 6.0168e-03,\n",
       "           1.1545e-01, 8.6530e-01],\n",
       "          [5.6577e-03, 6.8831e-06, 2.6207e-06,  ..., 1.2404e-01,\n",
       "           2.6590e-02, 8.3672e-01],\n",
       "          [1.5991e-03, 2.8521e-03, 1.0589e-02,  ..., 3.7004e-03,\n",
       "           3.4699e-03, 9.3522e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[2.4078e-03, 3.6420e-01, 7.6618e-02,  ..., 4.8312e-04,\n",
       "           6.1684e-04, 5.1793e-01],\n",
       "          [2.4886e-02, 1.4034e-02, 3.8108e-03,  ..., 3.3634e-05,\n",
       "           9.2560e-06, 8.1037e-01],\n",
       "          [2.2522e-02, 6.9298e-03, 1.4975e-02,  ..., 9.2043e-06,\n",
       "           6.1818e-05, 9.0715e-01],\n",
       "          ...,\n",
       "          [5.6105e-02, 1.2059e-04, 4.9904e-06,  ..., 1.4295e-01,\n",
       "           2.6727e-02, 7.0901e-01],\n",
       "          [1.2817e-01, 2.3999e-05, 2.3031e-05,  ..., 4.7400e-02,\n",
       "           8.2839e-02, 6.1527e-01],\n",
       "          [1.4112e-03, 1.7794e-02, 1.4820e-02,  ..., 2.1429e-03,\n",
       "           2.6056e-03, 8.7460e-01]],\n",
       "\n",
       "         [[1.1809e-02, 1.2224e-03, 2.1562e-03,  ..., 2.4017e-03,\n",
       "           2.6730e-03, 8.0637e-01],\n",
       "          [2.3761e-03, 3.9715e-03, 6.2083e-03,  ..., 3.1416e-03,\n",
       "           3.4881e-03, 8.7894e-01],\n",
       "          [7.7046e-03, 5.9349e-03, 2.1583e-02,  ..., 3.1388e-03,\n",
       "           3.2058e-03, 8.6713e-01],\n",
       "          ...,\n",
       "          [1.1513e-02, 2.1439e-05, 2.2266e-05,  ..., 1.4475e-02,\n",
       "           4.2478e-03, 9.6182e-01],\n",
       "          [1.3861e-02, 1.0617e-05, 5.0800e-06,  ..., 2.5723e-02,\n",
       "           6.3499e-03, 9.4860e-01],\n",
       "          [8.9509e-04, 4.2519e-04, 4.5650e-04,  ..., 1.1906e-03,\n",
       "           1.0199e-03, 9.6270e-01]],\n",
       "\n",
       "         [[1.9052e-03, 1.1329e-03, 2.2338e-03,  ..., 5.4349e-03,\n",
       "           1.1775e-04, 9.6430e-01],\n",
       "          [1.1870e-02, 2.5205e-02, 1.9801e-02,  ..., 7.9706e-07,\n",
       "           4.9309e-05, 9.2177e-01],\n",
       "          [2.7364e-02, 3.6217e-02, 3.6359e-03,  ..., 4.5937e-06,\n",
       "           3.6345e-06, 9.2699e-01],\n",
       "          ...,\n",
       "          [5.7510e-04, 4.5298e-08, 3.2007e-07,  ..., 1.1611e-02,\n",
       "           3.1428e-02, 9.4261e-01],\n",
       "          [3.3751e-02, 1.0389e-05, 4.8903e-06,  ..., 2.0561e-01,\n",
       "           1.7151e-02, 7.3956e-01],\n",
       "          [3.8981e-04, 6.3165e-04, 1.1920e-02,  ..., 8.5089e-03,\n",
       "           1.2735e-03, 8.5771e-01]]]], grad_fn=<SoftmaxBackward0>), tensor([[[[2.0766e-03, 9.3989e-05, 5.4355e-05,  ..., 2.4907e-04,\n",
       "           6.4929e-04, 9.9470e-01],\n",
       "          [7.7219e-03, 2.2197e-03, 1.8270e-02,  ..., 4.8656e-06,\n",
       "           8.2705e-05, 9.6881e-01],\n",
       "          [7.7063e-03, 2.6048e-02, 7.9336e-03,  ..., 1.4642e-05,\n",
       "           1.8187e-05, 9.5647e-01],\n",
       "          ...,\n",
       "          [5.4882e-04, 1.8487e-06, 2.8402e-06,  ..., 2.9403e-03,\n",
       "           2.3707e-02, 9.6775e-01],\n",
       "          [2.9705e-04, 2.0189e-05, 1.3335e-05,  ..., 1.6736e-01,\n",
       "           9.3802e-02, 6.8736e-01],\n",
       "          [1.0723e-03, 2.0526e-04, 2.6804e-03,  ..., 2.7773e-04,\n",
       "           7.1350e-04, 9.7760e-01]],\n",
       "\n",
       "         [[5.8584e-04, 2.6297e-02, 3.7900e-03,  ..., 5.8434e-03,\n",
       "           2.2667e-03, 9.0712e-01],\n",
       "          [1.4743e-01, 8.9592e-02, 1.5053e-01,  ..., 1.8022e-05,\n",
       "           3.4503e-05, 5.3312e-01],\n",
       "          [8.1163e-04, 9.5304e-01, 7.2626e-03,  ..., 7.0045e-06,\n",
       "           4.1936e-07, 2.1500e-02],\n",
       "          ...,\n",
       "          [7.9470e-05, 3.5345e-06, 6.1580e-05,  ..., 8.7093e-02,\n",
       "           8.0259e-02, 3.1320e-01],\n",
       "          [1.5793e-05, 1.5109e-06, 9.3624e-06,  ..., 8.3841e-01,\n",
       "           3.2727e-02, 5.1431e-02],\n",
       "          [1.1765e-03, 4.6162e-03, 5.5039e-03,  ..., 1.1433e-02,\n",
       "           3.5582e-03, 8.8809e-01]],\n",
       "\n",
       "         [[1.2673e-03, 5.7234e-04, 6.3746e-04,  ..., 1.5389e-03,\n",
       "           8.2774e-04, 9.8738e-01],\n",
       "          [1.2833e-01, 4.2485e-02, 1.4106e-01,  ..., 5.9906e-03,\n",
       "           2.9740e-03, 4.9907e-01],\n",
       "          [9.7670e-02, 4.8760e-02, 1.3228e-01,  ..., 4.0646e-03,\n",
       "           1.4933e-03, 5.7161e-01],\n",
       "          ...,\n",
       "          [1.8906e-02, 1.5107e-03, 3.0095e-03,  ..., 3.5069e-02,\n",
       "           1.8813e-02, 3.5309e-01],\n",
       "          [1.2778e-02, 1.2553e-03, 2.4268e-03,  ..., 1.4489e-02,\n",
       "           9.8767e-03, 2.5759e-01],\n",
       "          [9.6786e-04, 7.9969e-04, 1.6639e-03,  ..., 4.7687e-03,\n",
       "           4.1148e-03, 9.6182e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[1.2315e-03, 7.7186e-04, 3.1389e-04,  ..., 8.5750e-03,\n",
       "           7.3956e-03, 9.5531e-01],\n",
       "          [7.2081e-02, 2.7611e-02, 5.7215e-02,  ..., 4.3854e-04,\n",
       "           1.8974e-04, 8.2299e-01],\n",
       "          [3.6170e-02, 2.4147e-02, 1.4701e-02,  ..., 1.8675e-04,\n",
       "           8.3456e-05, 9.1001e-01],\n",
       "          ...,\n",
       "          [8.5368e-03, 1.4292e-02, 1.2503e-02,  ..., 3.0242e-02,\n",
       "           1.2477e-02, 2.1551e-01],\n",
       "          [7.9328e-03, 1.7160e-02, 4.6085e-03,  ..., 4.5183e-02,\n",
       "           2.0323e-02, 2.5536e-01],\n",
       "          [8.9079e-03, 1.4794e-03, 1.4243e-03,  ..., 2.4264e-03,\n",
       "           1.6552e-03, 9.5103e-01]],\n",
       "\n",
       "         [[1.7030e-03, 1.1542e-04, 1.7026e-03,  ..., 2.7792e-05,\n",
       "           8.4227e-05, 9.9502e-01],\n",
       "          [6.7852e-03, 1.2320e-03, 1.4895e-01,  ..., 9.5130e-06,\n",
       "           5.4843e-05, 8.2818e-01],\n",
       "          [1.5136e-03, 4.4047e-04, 2.2367e-02,  ..., 3.0819e-05,\n",
       "           1.2693e-04, 9.4293e-01],\n",
       "          ...,\n",
       "          [2.6954e-03, 4.0937e-06, 7.4716e-06,  ..., 2.1151e-03,\n",
       "           1.2021e-02, 9.7665e-01],\n",
       "          [8.0627e-04, 4.3967e-06, 1.0210e-05,  ..., 3.1369e-03,\n",
       "           1.0043e-02, 9.8202e-01],\n",
       "          [8.4388e-04, 6.5384e-03, 1.4662e-02,  ..., 1.1175e-03,\n",
       "           2.5644e-04, 9.3878e-01]],\n",
       "\n",
       "         [[6.9746e-04, 3.6721e-03, 5.0912e-03,  ..., 6.8030e-03,\n",
       "           2.5854e-03, 9.0721e-01],\n",
       "          [3.0691e-04, 7.1666e-03, 5.0112e-02,  ..., 2.2080e-02,\n",
       "           5.5616e-03, 1.5588e-01],\n",
       "          [3.5546e-04, 3.5964e-03, 1.4824e-02,  ..., 5.6868e-02,\n",
       "           1.1469e-02, 2.1889e-01],\n",
       "          ...,\n",
       "          [8.6547e-03, 2.6231e-04, 1.3916e-03,  ..., 1.8143e-01,\n",
       "           1.0891e-01, 4.2713e-01],\n",
       "          [1.7469e-02, 9.1580e-05, 5.4657e-04,  ..., 1.5912e-01,\n",
       "           7.2962e-02, 5.2148e-01],\n",
       "          [2.0324e-03, 9.0607e-04, 1.6326e-03,  ..., 2.6123e-03,\n",
       "           1.2450e-03, 9.3900e-01]]]], grad_fn=<SoftmaxBackward0>), tensor([[[[4.7035e-04, 6.6273e-04, 3.1548e-04,  ..., 4.6880e-01,\n",
       "           2.4298e-01, 4.0880e-03],\n",
       "          [2.5124e-02, 2.2906e-02, 2.4144e-02,  ..., 6.3782e-03,\n",
       "           4.3502e-03, 5.8847e-01],\n",
       "          [1.8390e-02, 2.2016e-02, 1.5878e-02,  ..., 2.5119e-03,\n",
       "           1.2242e-03, 7.1027e-01],\n",
       "          ...,\n",
       "          [2.0598e-02, 4.8754e-03, 7.9941e-03,  ..., 7.5951e-03,\n",
       "           6.9068e-03, 7.7588e-01],\n",
       "          [2.4006e-02, 5.2057e-03, 5.5154e-03,  ..., 1.2439e-02,\n",
       "           9.7868e-03, 7.3806e-01],\n",
       "          [1.8664e-03, 4.5269e-04, 6.8492e-04,  ..., 1.7699e-04,\n",
       "           1.9027e-04, 9.8310e-01]],\n",
       "\n",
       "         [[1.4092e-02, 5.3038e-04, 1.1395e-03,  ..., 1.5791e-01,\n",
       "           4.3015e-02, 3.5375e-01],\n",
       "          [2.0374e-02, 1.3499e-01, 8.6120e-02,  ..., 4.3970e-03,\n",
       "           1.2781e-03, 6.4809e-01],\n",
       "          [8.6208e-03, 4.0958e-02, 1.1124e-01,  ..., 8.9019e-04,\n",
       "           4.2454e-04, 7.7233e-01],\n",
       "          ...,\n",
       "          [1.8425e-02, 1.5793e-04, 4.5628e-04,  ..., 6.8182e-02,\n",
       "           2.8804e-02, 7.4002e-01],\n",
       "          [8.0549e-03, 8.2522e-05, 2.6153e-04,  ..., 8.1099e-02,\n",
       "           4.3911e-02, 7.4114e-01],\n",
       "          [7.0421e-03, 5.6429e-03, 9.7099e-03,  ..., 2.8549e-03,\n",
       "           3.9207e-03, 8.9401e-01]],\n",
       "\n",
       "         [[2.6524e-03, 8.9729e-03, 1.0740e-02,  ..., 6.5617e-02,\n",
       "           3.0440e-02, 7.5051e-01],\n",
       "          [1.7489e-03, 2.1253e-02, 2.4756e-02,  ..., 6.9484e-04,\n",
       "           3.3506e-04, 9.2144e-01],\n",
       "          [5.4658e-04, 4.4043e-03, 8.6245e-02,  ..., 2.4847e-05,\n",
       "           2.9130e-05, 8.9597e-01],\n",
       "          ...,\n",
       "          [4.3482e-03, 6.6646e-04, 2.2082e-04,  ..., 6.2332e-02,\n",
       "           1.8985e-02, 6.7506e-01],\n",
       "          [3.5593e-03, 2.5087e-04, 3.8919e-04,  ..., 7.6221e-02,\n",
       "           2.7108e-02, 6.4265e-01],\n",
       "          [2.1206e-03, 3.4233e-03, 1.7516e-03,  ..., 7.7520e-03,\n",
       "           2.6020e-03, 9.2584e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[6.5851e-03, 4.7983e-04, 2.4464e-04,  ..., 1.4406e-01,\n",
       "           8.9366e-02, 1.3366e-01],\n",
       "          [4.2356e-03, 3.5285e-02, 1.4380e-01,  ..., 6.1142e-02,\n",
       "           4.6399e-02, 3.7137e-01],\n",
       "          [5.2088e-03, 2.6477e-02, 1.2102e-01,  ..., 3.9831e-02,\n",
       "           4.3164e-02, 4.0470e-01],\n",
       "          ...,\n",
       "          [2.2568e-01, 1.4019e-03, 1.4419e-04,  ..., 5.2635e-02,\n",
       "           4.0421e-02, 4.0424e-01],\n",
       "          [1.4945e-01, 1.6494e-03, 1.1615e-04,  ..., 1.6082e-02,\n",
       "           1.0805e-02, 4.7293e-01],\n",
       "          [3.9387e-03, 1.4207e-03, 1.6236e-03,  ..., 2.1423e-03,\n",
       "           2.7449e-03, 8.9299e-01]],\n",
       "\n",
       "         [[1.0249e-02, 1.6112e-03, 3.6532e-04,  ..., 1.0044e-02,\n",
       "           8.7733e-03, 9.2081e-01],\n",
       "          [5.5742e-03, 9.4551e-03, 2.4414e-02,  ..., 3.0583e-04,\n",
       "           6.7185e-04, 8.8026e-01],\n",
       "          [1.1500e-03, 2.4210e-02, 9.7911e-04,  ..., 1.6233e-04,\n",
       "           3.2017e-05, 9.6540e-01],\n",
       "          ...,\n",
       "          [3.3294e-02, 9.8463e-06, 4.8273e-05,  ..., 5.8140e-02,\n",
       "           1.5310e-01, 6.5007e-01],\n",
       "          [1.0561e-02, 1.6665e-05, 2.5446e-05,  ..., 5.4991e-01,\n",
       "           1.4988e-01, 1.8256e-01],\n",
       "          [5.4669e-03, 1.3732e-03, 1.9164e-03,  ..., 8.3701e-03,\n",
       "           1.1559e-02, 9.2694e-01]],\n",
       "\n",
       "         [[4.2574e-03, 1.6708e-04, 8.8940e-05,  ..., 3.5752e-02,\n",
       "           2.6924e-02, 7.4861e-01],\n",
       "          [6.9672e-04, 6.3704e-02, 5.2452e-03,  ..., 1.2793e-05,\n",
       "           5.4797e-06, 9.2007e-01],\n",
       "          [2.3746e-04, 7.6609e-03, 7.7575e-02,  ..., 1.1274e-05,\n",
       "           6.6618e-06, 9.0474e-01],\n",
       "          ...,\n",
       "          [5.8084e-03, 4.4355e-06, 7.8248e-06,  ..., 2.2688e-02,\n",
       "           4.4504e-03, 9.4662e-01],\n",
       "          [3.5850e-03, 3.2957e-06, 6.3866e-06,  ..., 3.4684e-02,\n",
       "           3.8233e-02, 8.9597e-01],\n",
       "          [1.6714e-03, 4.1191e-03, 4.0474e-03,  ..., 2.2188e-03,\n",
       "           1.3894e-03, 9.5914e-01]]]], grad_fn=<SoftmaxBackward0>), tensor([[[[2.4828e-01, 7.6153e-02, 1.4744e-02,  ..., 3.4117e-02,\n",
       "           3.9385e-02, 3.6441e-02],\n",
       "          [2.6078e-02, 1.0824e-01, 7.4377e-02,  ..., 2.6190e-02,\n",
       "           1.7059e-02, 4.8904e-02],\n",
       "          [1.1679e-02, 1.0215e-01, 2.0298e-01,  ..., 1.4725e-02,\n",
       "           5.6741e-03, 2.7353e-02],\n",
       "          ...,\n",
       "          [4.7641e-01, 7.1359e-02, 2.4565e-03,  ..., 1.2791e-02,\n",
       "           8.4812e-03, 1.8400e-01],\n",
       "          [6.7097e-01, 2.1192e-02, 8.0953e-04,  ..., 8.6137e-03,\n",
       "           9.6266e-03, 1.0975e-01],\n",
       "          [1.2757e-04, 1.1846e-03, 1.0248e-03,  ..., 4.4744e-04,\n",
       "           5.9644e-04, 9.8244e-01]],\n",
       "\n",
       "         [[9.1943e-04, 1.3673e-04, 2.2098e-04,  ..., 1.5468e-01,\n",
       "           3.4344e-02, 6.1900e-01],\n",
       "          [8.5702e-05, 5.5880e-03, 6.9661e-03,  ..., 3.0021e-03,\n",
       "           1.3074e-03, 8.7409e-01],\n",
       "          [7.4562e-05, 2.3288e-02, 2.6855e-02,  ..., 3.1146e-03,\n",
       "           1.2789e-03, 8.6253e-01],\n",
       "          ...,\n",
       "          [3.8691e-04, 6.4724e-04, 4.3855e-04,  ..., 1.1868e-02,\n",
       "           5.8928e-03, 9.0923e-01],\n",
       "          [8.2214e-04, 6.5190e-04, 4.1999e-04,  ..., 1.7565e-02,\n",
       "           7.2768e-03, 8.5490e-01],\n",
       "          [1.6430e-04, 5.5587e-04, 4.9243e-04,  ..., 3.5455e-04,\n",
       "           3.2866e-04, 9.9023e-01]],\n",
       "\n",
       "         [[7.0930e-04, 1.3877e-04, 5.7204e-06,  ..., 1.3282e-02,\n",
       "           6.1808e-03, 9.5246e-01],\n",
       "          [3.1349e-04, 1.8925e-02, 1.5926e-02,  ..., 1.4938e-02,\n",
       "           4.0036e-03, 7.0617e-01],\n",
       "          [3.3723e-04, 4.1354e-02, 2.0984e-02,  ..., 3.2445e-02,\n",
       "           6.9295e-03, 4.3465e-01],\n",
       "          ...,\n",
       "          [5.2240e-04, 1.1139e-04, 1.7122e-05,  ..., 1.3649e-02,\n",
       "           5.5139e-03, 9.3912e-01],\n",
       "          [6.2922e-04, 7.8938e-05, 1.8507e-05,  ..., 2.0378e-02,\n",
       "           6.9760e-03, 9.3637e-01],\n",
       "          [3.9887e-04, 1.2047e-03, 3.0152e-04,  ..., 1.2082e-03,\n",
       "           9.8455e-04, 9.4684e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[3.3118e-01, 2.4829e-03, 8.8136e-04,  ..., 1.1105e-01,\n",
       "           2.7331e-02, 3.1907e-01],\n",
       "          [7.1885e-04, 3.5719e-02, 2.2329e-02,  ..., 9.1930e-05,\n",
       "           3.9671e-05, 2.2790e-01],\n",
       "          [7.3910e-04, 4.7256e-02, 8.9732e-02,  ..., 8.8592e-05,\n",
       "           6.8402e-05, 4.2055e-01],\n",
       "          ...,\n",
       "          [1.3601e-01, 4.1418e-04, 6.7040e-04,  ..., 1.9350e-01,\n",
       "           5.0055e-02, 4.3337e-01],\n",
       "          [6.8691e-02, 2.2223e-04, 5.5976e-04,  ..., 1.4538e-01,\n",
       "           7.1128e-02, 5.7112e-01],\n",
       "          [2.5884e-03, 4.0990e-03, 3.1471e-03,  ..., 3.5756e-03,\n",
       "           2.6580e-03, 9.4034e-01]],\n",
       "\n",
       "         [[7.3693e-03, 4.2523e-04, 1.0730e-04,  ..., 1.9901e-02,\n",
       "           5.1910e-02, 8.7053e-01],\n",
       "          [3.9105e-05, 2.0133e-03, 9.1391e-04,  ..., 1.9731e-04,\n",
       "           7.8562e-04, 9.7700e-01],\n",
       "          [8.4445e-06, 4.0176e-03, 2.9804e-03,  ..., 3.0038e-05,\n",
       "           1.1590e-04, 9.7631e-01],\n",
       "          ...,\n",
       "          [6.8703e-04, 1.3206e-04, 3.1374e-05,  ..., 4.7849e-04,\n",
       "           4.9364e-04, 9.9423e-01],\n",
       "          [2.0611e-03, 2.7375e-04, 4.7751e-05,  ..., 8.4580e-04,\n",
       "           5.4521e-04, 9.8754e-01],\n",
       "          [6.9512e-05, 3.5341e-04, 3.5123e-04,  ..., 3.9185e-04,\n",
       "           6.6232e-04, 9.9602e-01]],\n",
       "\n",
       "         [[7.3325e-02, 1.0067e-03, 1.3361e-03,  ..., 2.8933e-01,\n",
       "           8.0085e-02, 1.8875e-01],\n",
       "          [5.7953e-03, 1.1192e-01, 3.5810e-02,  ..., 2.8407e-03,\n",
       "           7.8484e-04, 7.4296e-01],\n",
       "          [2.2809e-03, 2.7295e-01, 3.0093e-02,  ..., 9.7054e-04,\n",
       "           1.0138e-04, 5.9830e-01],\n",
       "          ...,\n",
       "          [1.5507e-02, 1.0799e-03, 1.1384e-03,  ..., 8.9505e-02,\n",
       "           1.4397e-02, 5.5089e-01],\n",
       "          [7.3104e-03, 3.6226e-04, 4.1624e-04,  ..., 1.2055e-01,\n",
       "           1.2150e-02, 6.0147e-01],\n",
       "          [9.3573e-03, 3.3619e-03, 1.9629e-03,  ..., 1.3144e-02,\n",
       "           3.6934e-03, 9.0171e-01]]]], grad_fn=<SoftmaxBackward0>), tensor([[[[7.1177e-03, 6.9498e-04, 1.2308e-03,  ..., 2.0551e-02,\n",
       "           2.6189e-02, 6.5004e-01],\n",
       "          [1.6045e-03, 8.2400e-03, 5.5988e-03,  ..., 1.5270e-02,\n",
       "           9.8007e-03, 7.2114e-01],\n",
       "          [1.1322e-03, 4.8473e-04, 2.5434e-02,  ..., 9.1547e-03,\n",
       "           1.0991e-02, 4.5305e-01],\n",
       "          ...,\n",
       "          [2.2526e-03, 2.4173e-04, 4.0878e-04,  ..., 6.4190e-02,\n",
       "           5.6469e-02, 5.6156e-01],\n",
       "          [2.0591e-03, 5.9423e-05, 3.9663e-04,  ..., 2.2229e-02,\n",
       "           9.6967e-02, 6.0171e-01],\n",
       "          [4.3050e-04, 1.6932e-04, 3.6669e-04,  ..., 1.7616e-03,\n",
       "           1.1266e-03, 9.6015e-01]],\n",
       "\n",
       "         [[8.7028e-04, 5.1363e-04, 2.4156e-03,  ..., 6.2815e-03,\n",
       "           4.1553e-03, 9.0809e-01],\n",
       "          [1.4552e-04, 5.7179e-04, 3.6415e-04,  ..., 2.7590e-04,\n",
       "           2.9384e-04, 9.4058e-01],\n",
       "          [7.8161e-04, 3.0227e-03, 7.1874e-04,  ..., 1.2350e-03,\n",
       "           5.2216e-04, 9.5545e-01],\n",
       "          ...,\n",
       "          [6.2073e-04, 9.7618e-04, 1.0281e-03,  ..., 7.1582e-04,\n",
       "           5.2971e-04, 9.6043e-01],\n",
       "          [7.2036e-04, 1.0938e-03, 8.0021e-04,  ..., 1.6068e-03,\n",
       "           6.9197e-04, 9.6003e-01],\n",
       "          [7.4738e-04, 1.5493e-03, 9.5348e-04,  ..., 5.6177e-03,\n",
       "           4.1976e-03, 9.3635e-01]],\n",
       "\n",
       "         [[4.2019e-02, 1.4567e-03, 8.5989e-04,  ..., 6.7629e-02,\n",
       "           2.2176e-02, 6.8848e-01],\n",
       "          [1.3314e-02, 3.3064e-02, 1.0211e-03,  ..., 4.5995e-03,\n",
       "           2.9694e-03, 9.0650e-01],\n",
       "          [1.7185e-02, 9.9502e-03, 9.0098e-03,  ..., 7.8967e-03,\n",
       "           2.8634e-03, 8.0210e-01],\n",
       "          ...,\n",
       "          [8.3290e-02, 1.0973e-03, 4.8665e-04,  ..., 1.0165e-01,\n",
       "           8.0597e-03, 6.3725e-01],\n",
       "          [2.7722e-02, 5.3115e-04, 2.4002e-04,  ..., 1.6388e-02,\n",
       "           9.0255e-02, 8.1388e-01],\n",
       "          [1.1871e-03, 6.7415e-04, 1.3477e-03,  ..., 1.9582e-03,\n",
       "           3.3327e-03, 9.4543e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[1.0893e-06, 1.2796e-04, 1.4659e-05,  ..., 2.7015e-04,\n",
       "           2.6645e-04, 9.9703e-01],\n",
       "          [1.4695e-05, 1.1343e-03, 8.7380e-04,  ..., 5.3658e-04,\n",
       "           4.6744e-04, 9.7314e-01],\n",
       "          [5.4711e-06, 1.1964e-03, 3.2994e-04,  ..., 1.8035e-04,\n",
       "           1.2422e-04, 9.8849e-01],\n",
       "          ...,\n",
       "          [2.0007e-05, 2.9903e-04, 9.2928e-05,  ..., 1.3644e-03,\n",
       "           1.1804e-03, 9.8009e-01],\n",
       "          [4.2624e-06, 4.7832e-05, 1.4986e-05,  ..., 6.6239e-04,\n",
       "           4.7397e-04, 9.9528e-01],\n",
       "          [3.3116e-05, 9.5201e-04, 7.7402e-04,  ..., 7.4159e-04,\n",
       "           4.3737e-04, 9.7534e-01]],\n",
       "\n",
       "         [[1.5106e-03, 2.4434e-04, 7.7491e-05,  ..., 2.6439e-02,\n",
       "           4.3384e-03, 8.9264e-01],\n",
       "          [3.3825e-04, 7.4515e-03, 7.4078e-03,  ..., 4.2667e-03,\n",
       "           6.6814e-04, 7.7914e-01],\n",
       "          [2.5465e-04, 1.5082e-02, 2.7172e-02,  ..., 5.5686e-03,\n",
       "           5.8868e-04, 6.8735e-01],\n",
       "          ...,\n",
       "          [5.2686e-03, 5.3369e-04, 1.1266e-04,  ..., 9.4511e-03,\n",
       "           2.5754e-03, 9.2855e-01],\n",
       "          [9.8375e-03, 3.6915e-04, 6.0164e-05,  ..., 2.5502e-02,\n",
       "           5.4945e-03, 8.9259e-01],\n",
       "          [1.0947e-03, 3.4445e-04, 5.1649e-04,  ..., 2.2293e-03,\n",
       "           1.2193e-03, 9.3666e-01]],\n",
       "\n",
       "         [[1.1652e-01, 5.9362e-03, 1.6778e-03,  ..., 4.6654e-02,\n",
       "           3.2965e-02, 1.5880e-01],\n",
       "          [2.4116e-03, 6.1936e-02, 8.7273e-02,  ..., 6.7832e-03,\n",
       "           2.8150e-03, 6.3969e-01],\n",
       "          [5.6649e-03, 1.1698e-01, 8.9833e-03,  ..., 7.7169e-03,\n",
       "           9.2859e-04, 6.4685e-01],\n",
       "          ...,\n",
       "          [2.0374e-01, 1.2493e-03, 9.1323e-04,  ..., 4.0905e-02,\n",
       "           5.3077e-02, 3.9813e-01],\n",
       "          [1.7970e-01, 1.4009e-03, 5.3417e-04,  ..., 3.7965e-02,\n",
       "           2.9685e-02, 5.3650e-01],\n",
       "          [2.9513e-03, 1.3162e-03, 1.7028e-03,  ..., 4.4137e-03,\n",
       "           5.4438e-03, 9.1593e-01]]]], grad_fn=<SoftmaxBackward0>), tensor([[[[7.5613e-03, 1.2148e-02, 1.8289e-02,  ..., 1.6546e-02,\n",
       "           1.6524e-02, 1.3907e-01],\n",
       "          [9.1280e-03, 1.6515e-02, 6.7816e-03,  ..., 6.0123e-03,\n",
       "           6.2577e-03, 7.6006e-01],\n",
       "          [7.8132e-03, 1.9009e-02, 1.1693e-02,  ..., 4.3159e-03,\n",
       "           3.4882e-03, 7.8297e-01],\n",
       "          ...,\n",
       "          [9.1896e-03, 5.7568e-03, 5.6531e-03,  ..., 2.9418e-02,\n",
       "           2.0829e-02, 5.0704e-01],\n",
       "          [5.1966e-03, 2.1444e-03, 3.9100e-03,  ..., 2.1076e-02,\n",
       "           1.0903e-02, 6.2047e-01],\n",
       "          [2.3174e-02, 2.6234e-02, 3.7814e-02,  ..., 2.6832e-02,\n",
       "           2.4906e-02, 2.7988e-02]],\n",
       "\n",
       "         [[7.2264e-02, 9.9608e-03, 4.1805e-03,  ..., 2.0115e-01,\n",
       "           8.9798e-02, 1.6901e-01],\n",
       "          [2.2840e-02, 3.8580e-01, 8.4280e-03,  ..., 4.0192e-02,\n",
       "           1.6072e-02, 6.6876e-02],\n",
       "          [6.9847e-03, 1.6760e-02, 1.5253e-01,  ..., 1.9738e-02,\n",
       "           2.2018e-02, 2.5285e-01],\n",
       "          ...,\n",
       "          [1.8230e-02, 1.5081e-03, 7.9936e-04,  ..., 6.7320e-01,\n",
       "           3.4334e-02, 1.0371e-02],\n",
       "          [1.4819e-02, 1.2745e-03, 4.3403e-04,  ..., 6.3614e-02,\n",
       "           7.3710e-01, 1.4723e-02],\n",
       "          [5.3078e-03, 2.2454e-02, 3.2844e-02,  ..., 3.2294e-02,\n",
       "           4.8220e-02, 4.5191e-01]],\n",
       "\n",
       "         [[1.4861e-02, 8.7510e-03, 1.8315e-03,  ..., 2.7068e-01,\n",
       "           1.5550e-01, 9.0918e-02],\n",
       "          [7.7898e-03, 3.0960e-02, 1.2236e-02,  ..., 7.9628e-02,\n",
       "           2.2809e-02, 5.4231e-01],\n",
       "          [8.9238e-03, 4.3418e-02, 2.4901e-02,  ..., 8.0654e-02,\n",
       "           2.4321e-02, 4.5321e-01],\n",
       "          ...,\n",
       "          [1.3392e-02, 4.5059e-03, 1.1205e-03,  ..., 2.0763e-01,\n",
       "           9.2129e-02, 1.8310e-01],\n",
       "          [1.8457e-02, 3.3405e-03, 1.0794e-03,  ..., 2.0629e-01,\n",
       "           8.7656e-02, 2.2936e-01],\n",
       "          [3.9142e-02, 2.9859e-02, 3.1492e-02,  ..., 7.2060e-02,\n",
       "           7.7694e-02, 4.4753e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[2.5640e-02, 1.6659e-02, 6.1076e-03,  ..., 1.3273e-01,\n",
       "           3.0631e-01, 4.9941e-02],\n",
       "          [2.1272e-02, 8.2529e-02, 8.0055e-03,  ..., 5.9505e-03,\n",
       "           1.2311e-02, 3.9185e-01],\n",
       "          [1.1455e-02, 5.4845e-02, 2.7313e-02,  ..., 6.0459e-03,\n",
       "           1.5306e-02, 4.0426e-01],\n",
       "          ...,\n",
       "          [3.3441e-02, 1.1487e-02, 5.6630e-03,  ..., 2.1888e-02,\n",
       "           3.4120e-02, 3.1681e-01],\n",
       "          [2.4447e-02, 1.3840e-02, 9.4665e-03,  ..., 1.0246e-02,\n",
       "           5.5490e-02, 4.9437e-01],\n",
       "          [4.3946e-02, 4.1850e-02, 3.7541e-02,  ..., 5.3720e-02,\n",
       "           4.3072e-02, 2.9933e-02]],\n",
       "\n",
       "         [[4.5916e-02, 1.4906e-02, 1.0092e-02,  ..., 1.4512e-01,\n",
       "           1.3585e-01, 3.7061e-02],\n",
       "          [1.2624e-02, 2.0359e-01, 5.9511e-03,  ..., 6.5025e-02,\n",
       "           3.8593e-02, 2.2846e-01],\n",
       "          [1.1050e-02, 7.1364e-03, 3.4446e-02,  ..., 2.4081e-02,\n",
       "           3.9998e-02, 3.5843e-01],\n",
       "          ...,\n",
       "          [2.6727e-02, 4.1124e-03, 3.4614e-03,  ..., 1.4374e-01,\n",
       "           1.4565e-01, 1.2963e-01],\n",
       "          [2.2455e-02, 3.6480e-03, 5.6226e-03,  ..., 6.7598e-02,\n",
       "           2.6542e-01, 1.9349e-01],\n",
       "          [1.9515e-02, 3.9274e-02, 5.2085e-02,  ..., 4.2725e-02,\n",
       "           4.0485e-02, 2.4171e-02]],\n",
       "\n",
       "         [[1.3568e-01, 1.9462e-02, 3.3931e-03,  ..., 2.0420e-01,\n",
       "           1.3709e-01, 6.2394e-02],\n",
       "          [1.5655e-02, 4.3804e-01, 1.1652e-02,  ..., 1.9579e-02,\n",
       "           1.8665e-02, 3.0023e-01],\n",
       "          [7.2301e-03, 7.6680e-03, 2.0077e-01,  ..., 1.3564e-02,\n",
       "           1.7031e-02, 5.1944e-01],\n",
       "          ...,\n",
       "          [3.9210e-02, 3.2023e-02, 2.5634e-03,  ..., 3.8380e-01,\n",
       "           5.3400e-02, 1.4656e-01],\n",
       "          [3.0948e-02, 1.3918e-02, 4.3983e-03,  ..., 5.4189e-02,\n",
       "           4.0839e-01, 2.2616e-01],\n",
       "          [1.3019e-02, 3.9770e-02, 1.1244e-02,  ..., 4.3042e-02,\n",
       "           5.9861e-02, 2.5202e-01]]]], grad_fn=<SoftmaxBackward0>)), cross_attentions=None)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert.bert(**inputs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
